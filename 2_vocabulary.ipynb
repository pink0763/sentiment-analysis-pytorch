{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build vocabulary and data iterator\n",
    "\n",
    "In this notebook we are going to create the vocabulary object that will be responsible for:\n",
    "- Creating dataset's vocabulary.\n",
    "- Filtering dataset in terms of the rare words occurrence and sentences lengths.\n",
    "- Mapping words to their numerical representation (word2index) and reverse (index2word).\n",
    "- Enabling the use of pre-trained word vectors.\n",
    "\n",
    "\n",
    "The second object to create is a data iterator whose task will be:\n",
    "- Sorting dataset examples.\n",
    "- Generating batches.\n",
    "- Sequence padding.\n",
    "- Enabling BatchIterator instance to iterate through all batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with importing all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to build the vocabulary class that includes all the features mentioned at the beginning of this notebook. We want our class to enable to use of pre-trained vectors and construct the weights matrix. To be able to perform that task, we have to supply the vocabulary model with a set of pre-trained vectors.\n",
    "\n",
    "Glove vectors can be downloaded from the following website:\n",
    "https://nlp.stanford.edu/projects/glove/\n",
    "<br>\n",
    "Fasttext word vectors can be found under the link:\n",
    "https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \n",
    "    \"\"\"The Vocab class is responsible for:\n",
    "    Creating dataset's vocabulary.\n",
    "    Filtering dataset in terms of the rare words occurrence and sentences lengths.\n",
    "    Mapping words to their numerical representation (word2index) and reverse (index2word).\n",
    "    Enabling the use of pre-trained word vectors.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pandas.DataFrame or numpy.ndarray\n",
    "        Pandas or numpy dataset containing in the first column input strings to process and target non-string \n",
    "        variable as last column.\n",
    "    target_col: int, optional (default=None)\n",
    "        Column index refering to targets strings to process.\n",
    "    word2index: dict, optional (default=None)\n",
    "        Specify the word2index mapping.\n",
    "    sos_token: str, optional (default='<SOS>')\n",
    "        Start of sentence token.\n",
    "    eos_token: str, optional (default='<EOS>')\n",
    "        End of sentence token.\n",
    "    unk_token: str, optional (default='<UNK>')\n",
    "        Token that represents unknown words.\n",
    "    pad_token: str, optional (default='<PAD>')\n",
    "        Token that represents padding.\n",
    "    min_word_count: float, optional (default=5)\n",
    "        Specify the minimum word count threshold to include a word in vocabulary if value > 1 was passed.\n",
    "        If min_word_count <= 1 then keep all words whose count is greater than the quantile=min_word_count\n",
    "        of the count distribution.\n",
    "    max_vocab_size: int, optional (default=None)\n",
    "        Maximum size of the vocabulary.\n",
    "    max_seq_len: float, optional (default=0.8)\n",
    "        Specify the maximum length of the sequence in the dataset, if max_seq_len > 1. If max_seq_len <= 1 then set\n",
    "        the maximum length to value corresponding to quantile=max_seq_len of lengths distribution. Trimm all\n",
    "        sequences whose lengths are greater than max_seq_len.\n",
    "    use_pretrained_vectors: boolean, optional (default=False)\n",
    "        Whether to use pre-trained Glove vectors.\n",
    "    glove_path: str, optional (default='Glove/')\n",
    "        Path to the directory that contains files with the Glove word vectors.\n",
    "    glove_name: str, optional (default='glove.6B.100d.txt')\n",
    "        Name of the Glove word vectors file. Available pretrained vectors:\n",
    "        glove.6B.50d.txt\n",
    "        glove.6B.100d.txt\n",
    "        glove.6B.200d.txt\n",
    "        glove.6B.300d.txt\n",
    "        glove.twitter.27B.50d.txt\n",
    "        To use different word vectors, load their file to the vectors directory (Glove/).\n",
    "    weights_file_name: str, optional (default='Glove/weights.npy')\n",
    "        The path and the name of the numpy file to which save weights vectors.\n",
    "\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError('Use min_word_count or max_vocab_size, not both!')\n",
    "        If both: min_word_count and max_vocab_size are provided.\n",
    "    FileNotFoundError\n",
    "        If the glove file doesn't exists in the given directory.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, dataset, target_col=None, word2index=None, sos_token='<SOS>', eos_token='<EOS>', unk_token='<UNK>',\n",
    "             pad_token='<PAD>', min_word_count=5, max_vocab_size=None, max_seq_len=0.8,\n",
    "             use_pretrained_vectors=False, glove_path='Glove/', glove_name='glove.6B.100d.txt',\n",
    "             weights_file_name='Glove/weights.npy'):\n",
    "        \n",
    "        # Convert pandas dataframe to numpy.ndarray\n",
    "        if isinstance(dataset, pd.DataFrame):\n",
    "            dataset = dataset.to_numpy()\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.target_col = target_col\n",
    "        \n",
    "        if self.target_col:\n",
    "            self.y_lengths = []\n",
    "            \n",
    "        self.x_lengths = []\n",
    "        self.word2idx_mapping = word2index\n",
    "        \n",
    "        # Define word2idx and idx2word as empty dictionaries\n",
    "        if self.word2idx_mapping:\n",
    "            self.word2index = self.word2idx_mapping\n",
    "        else:\n",
    "            self.word2index = defaultdict(dict)\n",
    "            self.index2word = defaultdict(dict)            \n",
    "        \n",
    "        # Instantiate special tokens\n",
    "        self.sos_token = sos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.unk_token = unk_token\n",
    "        self.pad_token = pad_token\n",
    "        \n",
    "        # Instantiate min_word_count, max_vocab_size and max_seq_len\n",
    "        self.min_word_count = min_word_count\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        self.use_pretrained_vectors = use_pretrained_vectors\n",
    "        \n",
    "        if self.use_pretrained_vectors: \n",
    "            self.glove_path = glove_path\n",
    "            self.glove_name = glove_name\n",
    "            self.weights_file_name = weights_file_name\n",
    "        \n",
    "        self.build_vocab()\n",
    "        \n",
    "        \n",
    "    def build_vocab(self):\n",
    "        \"\"\"Build the vocabulary, filter dataset sequences and create the weights matrix if specified.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Create a dictionary that maps words to their count\n",
    "        self.word_count = self.word2count()\n",
    "\n",
    "        # Trim the vocabulary\n",
    "        # Get rid of out-of-vocabulary words from the dataset\n",
    "        if self.min_word_count or self.max_vocab_size:\n",
    "            self.trimVocab()\n",
    "            self.trimDatasetVocab()\n",
    "\n",
    "        # Trim sequences in terms of length\n",
    "        if self.max_seq_len:\n",
    "            if self.x_lengths:\n",
    "                self.trimSeqLen()\n",
    "\n",
    "            else:\n",
    "                # Calculate sequences lengths\n",
    "                self.x_lengths = [len(seq.split()) for seq in self.dataset[:, 0]]\n",
    "                \n",
    "                if self.target_col:\n",
    "                    self.y_lengths = [len(seq.split()) for seq in self.dataset[:, self.target_col]]\n",
    "                    \n",
    "                self.trimSeqLen()                \n",
    "\n",
    "                \n",
    "        # Map each tokens to index\n",
    "        if not self.word2idx_mapping:\n",
    "            self.mapWord2index()\n",
    "               \n",
    "        # Crate index2word mapping\n",
    "        self.index2word = {index: word for word, index in self.word2index.items()}\n",
    "        \n",
    "        # Map dataset tokens to indices\n",
    "        self.mapWords2indices()\n",
    "        \n",
    "        # Create weights matrix based on Glove vectors\n",
    "        if self.use_pretrained_vectors:\n",
    "            self.glove_vectors()       \n",
    "        \n",
    "            \n",
    "    def word2count(self):\n",
    "        \"\"\"Count the number of words occurrences.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Instantiate the Counter object\n",
    "        word_count = Counter()\n",
    "\n",
    "        # Iterate through the dataset and count tokens\n",
    "        for line in self.dataset[:, 0]:\n",
    "            word_count.update(line.split())\n",
    "            \n",
    "            # Include strings from target column\n",
    "            if self.target_col:\n",
    "                for line in self.dataset[:, self.target_col]:\n",
    "                    word_count.update(line.split())\n",
    "            \n",
    "        return word_count\n",
    "    \n",
    "\n",
    "    def trimVocab(self):\n",
    "        \"\"\"Trim the vocabulary in terms of the minimum word count or the vocabulary maximum size.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Trim the vocabulary in terms of the minimum word count\n",
    "        if self.min_word_count and not self.max_vocab_size:\n",
    "            # If min_word_count <= 1, use the quantile approach\n",
    "            if self.min_word_count <= 1:\n",
    "                # Create the list of words count\n",
    "                word_stat = [count for count in self.word_count.values()]\n",
    "                # Calculate the quantile of words count\n",
    "                quantile = int(np.quantile(word_stat, self.min_word_count))\n",
    "                print('Trimmed vocabulary using as mininum count threashold: quantile({:3.2f}) = {}'.\\\n",
    "                      format(self.min_word_count, quantile))\n",
    "                # Filter words using quantile threshold\n",
    "                self.trimmed_word_count = {word: count for word, count in self.word_count.items() if count >= quantile}\n",
    "            # If min_word_count > 1 use standard approach\n",
    "            else:\n",
    "                # Filter words using count threshold\n",
    "                self.trimmed_word_count = {word: count for word, count in self.word_count.items()\\\n",
    "                                   if count >= self.min_word_count}\n",
    "                print('Trimmed vocabulary using as minimum count threashold: count = {:3.2f}'.format(self.min_word_count))\n",
    "                     \n",
    "        # Trim the vocabulary in terms of its maximum size\n",
    "        elif self.max_vocab_size and not self.min_word_count:\n",
    "            self.trimmed_word_count = {word: count for word, count in self.word_count.most_common(self.max_vocab_size)}\n",
    "            print('Trimmed vocabulary using maximum size of: {}'.format(self.max_vocab_size))\n",
    "        else:\n",
    "            raise ValueError('Use min_word_count or max_vocab_size, not both!')\n",
    "            \n",
    "        print('{}/{} tokens has been retained'.format(len(self.trimmed_word_count.keys()),\n",
    "                                                     len(self.word_count.keys())))\n",
    "\n",
    "    \n",
    "    def trimDatasetVocab(self):\n",
    "        \"\"\"Get rid of rare words from the dataset sequences.\n",
    "        \n",
    "        \"\"\"\n",
    "        for row in range(self.dataset.shape[0]):\n",
    "            trimmed_x = [word for word in self.dataset[row, 0].split() if word in self.trimmed_word_count.keys()]\n",
    "            self.x_lengths.append(len(trimmed_x))\n",
    "            self.dataset[row, 0] = ' '.join(trimmed_x)\n",
    "        print('Trimmed input strings vocabulary')\n",
    "                            \n",
    "        if self.target_col:\n",
    "            for row in range(self.dataset.shape[0]):\n",
    "                trimmed_y = [word for word in self.dataset[row, self.target_col].split()\\\n",
    "                             if word in self.trimmed_word_count.keys()]\n",
    "                self.y_lengths.append(len(trimmed_y))\n",
    "                self.dataset[row, self.target_col] = ' '.join(trimmed_y)\n",
    "            print('Trimmed target strings vocabulary')\n",
    "            \n",
    "                \n",
    "    def trimSeqLen(self):\n",
    "        \"\"\"Trim dataset sequences in terms of the length.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.max_seq_len <= 1:\n",
    "            x_threshold = int(np.quantile(self.x_lengths, self.max_seq_len)) \n",
    "            if self.target_col:\n",
    "                y_threshold = int(np.quantile(self.y_lengths, self.max_seq_len)) \n",
    "        else:\n",
    "            x_threshold = self.max_seq_len\n",
    "            if self.target_col:\n",
    "                y_threshold =  self.max_seq_len\n",
    "        \n",
    "        if self.target_col:      \n",
    "            for row in range(self.dataset.shape[0]):\n",
    "                x_truncated = ' '.join(self.dataset[row, 0].split()[:x_threshold])\\\n",
    "                if self.x_lengths[row] > x_threshold else self.dataset[row, 0]\n",
    "                \n",
    "                # Add 1 if the EOS token is going to be added to the sequence\n",
    "                self.x_lengths[row] = len(x_truncated.split()) if not self.eos_token else \\\n",
    "                                      len(x_truncated.split()) + 1\n",
    "                \n",
    "                self.dataset[row, 0] = x_truncated\n",
    "                \n",
    "                y_truncated = ' '.join(self.dataset[row, self.target_col].split()[:y_threshold])\\\n",
    "                if self.y_lengths[row] > y_threshold else self.dataset[row, self.target_col]\n",
    "                \n",
    "                # Add 1 or 2 to the length to inculde special tokens\n",
    "                y_length = len(y_truncated.split())\n",
    "                if self.sos_token and not self.eos_token:\n",
    "                    y_length = len(y_truncated.split()) + 1\n",
    "                elif self.eos_token and not self.sos_token:\n",
    "                    y_length = len(y_truncated.split()) + 1\n",
    "                elif self.sos_token and self.eos_token:\n",
    "                    y_length = len(y_truncated.split()) + 2\n",
    "                    \n",
    "                self.y_lengths[row] = y_length\n",
    "                \n",
    "                self.dataset[row, self.target_col] = y_truncated\n",
    "                \n",
    "            print('Trimmed input sequences lengths to the length of: {}'.format(x_threshold))\n",
    "            print('Trimmed target sequences lengths to the length of: {}'.format(y_threshold))\n",
    "            \n",
    "        else:\n",
    "            for row in range(self.dataset.shape[0]):\n",
    "\n",
    "                x_truncated = ' '.join(self.dataset[row, 0].split()[:x_threshold])\\\n",
    "                if self.x_lengths[row] > x_threshold else self.dataset[row, 0]\n",
    "                \n",
    "                # Add 1 if the EOS token is going to be added to the sequence\n",
    "                self.x_lengths[row] = len(x_truncated.split()) if not self.eos_token else \\\n",
    "                                      len(x_truncated.split()) + 1\n",
    "                \n",
    "                self.dataset[row, 0] = x_truncated\n",
    "                \n",
    "            print('Trimmed input sequences lengths to the length of: {}'.format(x_threshold))\n",
    "                \n",
    "        \n",
    "    def mapWord2index(self):\n",
    "        \"\"\"Populate vocabulary word2index dictionary.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Add special tokens as first elements in word2index dictionary\n",
    "        token_count = 0\n",
    "        for token in [self.pad_token, self.sos_token, self.eos_token, self.unk_token]:\n",
    "            if token:\n",
    "                self.word2index[token] = token_count\n",
    "                token_count += 1\n",
    "        \n",
    "        # If vocabulary is trimmed, use trimmed_word_count\n",
    "        if self.min_word_count or self.max_vocab_size:\n",
    "            for key in self.trimmed_word_count.keys():\n",
    "                self.word2index[key] = token_count\n",
    "                token_count += 1\n",
    "            \n",
    "        # If vocabulary is not trimmed, iterate through dataset    \n",
    "        else:\n",
    "            for line in self.dataset.iloc[:, 0]:\n",
    "                for word in line.split():\n",
    "                    if word not in self.word2index.keys():\n",
    "                        self.word2index[word] = token_count\n",
    "                        token_count += 1\n",
    "            # Include strings from target column\n",
    "            if self.target_col:\n",
    "                for line in self.dataset.iloc[:, self.target_col]:\n",
    "                    for word in line.split():\n",
    "                        if word not in self.word2index.keys():\n",
    "                            self.word2index[word] = token_count\n",
    "                            token_count += 1\n",
    "                            \n",
    "        self.word2index.default_factory = lambda: self.word2index[self.unk_token]\n",
    "                            \n",
    "        \n",
    "    def mapWords2indices(self):\n",
    "        \"\"\"Iterate through the dataset to map each word to its corresponding index.\n",
    "        Use special tokens if specified.\n",
    "        \n",
    "        \"\"\"\n",
    "        for row in range(self.dataset.shape[0]):\n",
    "            words2indices = []\n",
    "            for word in self.dataset[row, 0].split():\n",
    "                words2indices.append(self.word2index[word])\n",
    "                    \n",
    "            # Append the end of the sentence token\n",
    "            if self.eos_token:\n",
    "                words2indices.append(self.word2index[self.eos_token])\n",
    "                \n",
    "            self.dataset[row, 0] = np.array(words2indices)\n",
    "                \n",
    "        # Map strings from target column\n",
    "        if self.target_col:\n",
    "            for row in range(self.dataset.shape[0]):\n",
    "                words2indices = []\n",
    "                \n",
    "                # Insert the start of the sentence token\n",
    "                if self.sos_token:\n",
    "                    words2indices.append(self.word2index[self.sos_token])\n",
    "                    \n",
    "                for word in self.dataset[row, self.target_col].split():\n",
    "                    words2indices.append(self.word2index[word])\n",
    "\n",
    "                        \n",
    "                # Append the end of the sentence token\n",
    "                if self.eos_token:\n",
    "                    words2indices.append(self.word2index[self.eos_token])\n",
    "                    \n",
    "                self.dataset[row, self.target_col] = np.array(words2indices)\n",
    "           \n",
    "        print('Mapped words to indices')\n",
    "\n",
    "    \n",
    "    def glove_vectors(self):\n",
    "        \"\"\" Read glove vectors from a file, create the matrix of weights mapping vocabulary tokens to vectors.\n",
    "        Save the weights matrix to the numpy file.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Load Glove word vectors to the pandas dataframe\n",
    "        try:\n",
    "            gloves = pd.read_csv(self.glove_path + self.glove_name, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "        except FileNotFoundError:\n",
    "            print('File: {} not found in: {} directory'.format(self.glove_name, self.glove_path))\n",
    "            \n",
    "        # Map Glove words to vectors\n",
    "        print('Start creating glove_word2vector dictionary')\n",
    "        self.glove_word2vector = gloves.T.to_dict(orient='list')\n",
    "        \n",
    "        # Extract embedding dimension\n",
    "        emb_dim = int(re.findall('\\d+' ,self.glove_name)[-1])\n",
    "        # Length of the vocabulary\n",
    "        matrix_len = len(self.word2index)\n",
    "        # Initialize the weights matrix\n",
    "        weights_matrix = np.zeros((matrix_len, emb_dim))\n",
    "        words_found = 0\n",
    "\n",
    "        # Populate the weights matrix\n",
    "        for word, index in self.word2index.items():\n",
    "            try: \n",
    "                weights_matrix[index] = np.array(self.glove_word2vector[word])\n",
    "                words_found += 1\n",
    "            except KeyError:\n",
    "                # If vector wasn't found in Glove, initialize random vector\n",
    "                weights_matrix[index] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "         \n",
    "        # Save the weights matrix into numpy file\n",
    "        np.save(self.weights_file_name, weights_matrix, allow_pickle=False)\n",
    "        \n",
    "        # Delete glove_word2vector variable to free the memory\n",
    "        del self.glove_word2vector\n",
    "                        \n",
    "        print('Extracted {}/{} of pre-trained word vectors.'.format(words_found, matrix_len))\n",
    "        print('{} vectors initialized to random numbers'.format(matrix_len - words_found))\n",
    "        print('Weights vectors saved into {}'.format(self.weights_file_name))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Vocab class is ready, to test its functionality, firstly we have to load the dataset that will be processed and used to build the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set\n",
    "train_dataset = pd.read_csv('dataset/datasets_feat_clean/train_feat_clean.csv', \n",
    "                      usecols=['clean_review', 'polarity', 'word_count', 'label'],\n",
    "                      dtype={'clean_review': str, 'label': np.int16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the columns order\n",
    "train_dataset = train_dataset[['clean_review', 'polarity', 'word_count', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_review</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>amaze good wonderful film early ninety franchi...</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>wrong end see tell chick go crazy eat old woma...</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>guess emperor clothe see list pbs night hopefu...</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>earth well movie funny sweet good plot unique ...</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>doe eye high school student kathleen beller fi...</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        clean_review  polarity  word_count  \\\n",
       "0  amaze good wonderful film early ninety franchi...    0.2482         391   \n",
       "1  wrong end see tell chick go crazy eat old woma...    0.1763         145   \n",
       "2  guess emperor clothe see list pbs night hopefu...    0.1145         165   \n",
       "3  earth well movie funny sweet good plot unique ...    0.3810          55   \n",
       "4  doe eye high school student kathleen beller fi...    0.2095         688   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows from the dataset\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will instantiate the Vocab class, that will cause that the dataset processing begins. After it finished we will be able to access vocab attributes to check out whether all objects are created properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed vocabulary using maximum size of: 5000\n",
      "5000/130416 tokens has been retained\n",
      "Trimmed input strings vocabulary\n",
      "Trimmed input sequences lengths to the length of: 121\n",
      "Mapped words to indices\n"
     ]
    }
   ],
   "source": [
    "train_vocab = Vocab(train_dataset, target_col=None, word2index=None, sos_token='<SOS>', eos_token='<EOS>',\n",
    "                    unk_token='<UNK>', pad_token='<PAD>', min_word_count=None, max_vocab_size=5000, max_seq_len=0.8,\n",
    "                    use_pretrained_vectors=False, glove_path='glove/', glove_name='glove.6B.100d.txt',\n",
    "                    weights_file_name='glove/weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Vocab.mapWord2index.<locals>.<lambda>()>,\n",
       "            {'<PAD>': 0,\n",
       "             '<SOS>': 1,\n",
       "             '<EOS>': 2,\n",
       "             '<UNK>': 3,\n",
       "             'movie': 4,\n",
       "             'film': 5,\n",
       "             'like': 6,\n",
       "             'time': 7,\n",
       "             'good': 8,\n",
       "             'character': 9,\n",
       "             'watch': 10,\n",
       "             'see': 11,\n",
       "             'story': 12,\n",
       "             'think': 13,\n",
       "             'well': 14,\n",
       "             'scene': 15,\n",
       "             'great': 16,\n",
       "             'look': 17,\n",
       "             'know': 18,\n",
       "             'end': 19,\n",
       "             'people': 20,\n",
       "             'go': 21,\n",
       "             'bad': 22,\n",
       "             'get': 23,\n",
       "             'love': 24,\n",
       "             'act': 25,\n",
       "             'play': 26,\n",
       "             'way': 27,\n",
       "             'come': 28,\n",
       "             'thing': 29,\n",
       "             'find': 30,\n",
       "             'man': 31,\n",
       "             'make': 32,\n",
       "             'plot': 33,\n",
       "             'work': 34,\n",
       "             'actor': 35,\n",
       "             'want': 36,\n",
       "             'year': 37,\n",
       "             'little': 38,\n",
       "             'feel': 39,\n",
       "             'life': 40,\n",
       "             'try': 41,\n",
       "             'wrong': 42,\n",
       "             'give': 43,\n",
       "             'old': 44,\n",
       "             'take': 45,\n",
       "             'director': 46,\n",
       "             'lot': 47,\n",
       "             'interest': 48,\n",
       "             'funny': 49,\n",
       "             'real': 50,\n",
       "             'show': 51,\n",
       "             'guy': 52,\n",
       "             'woman': 53,\n",
       "             'performance': 54,\n",
       "             'leave': 55,\n",
       "             'say': 56,\n",
       "             'cast': 57,\n",
       "             'big': 58,\n",
       "             'live': 59,\n",
       "             'actually': 60,\n",
       "             'tell': 61,\n",
       "             'young': 62,\n",
       "             'new': 63,\n",
       "             'star': 64,\n",
       "             'start': 65,\n",
       "             'role': 66,\n",
       "             'long': 67,\n",
       "             'write': 68,\n",
       "             'point': 69,\n",
       "             'girl': 70,\n",
       "             'set': 71,\n",
       "             'day': 72,\n",
       "             'world': 73,\n",
       "             'turn': 74,\n",
       "             'horror': 75,\n",
       "             'fact': 76,\n",
       "             'pretty': 77,\n",
       "             'comedy': 78,\n",
       "             'kill': 79,\n",
       "             'action': 80,\n",
       "             'minute': 81,\n",
       "             'happen': 82,\n",
       "             'late': 83,\n",
       "             'right': 84,\n",
       "             'mean': 85,\n",
       "             'line': 86,\n",
       "             'need': 87,\n",
       "             'fan': 88,\n",
       "             'bite': 89,\n",
       "             'enjoy': 90,\n",
       "             'friend': 91,\n",
       "             'music': 92,\n",
       "             'script': 93,\n",
       "             'series': 94,\n",
       "             'original': 95,\n",
       "             'family': 96,\n",
       "             'begin': 97,\n",
       "             'kid': 98,\n",
       "             'believe': 99,\n",
       "             'shoot': 100,\n",
       "             'lead': 101,\n",
       "             'far': 102,\n",
       "             'kind': 103,\n",
       "             'run': 104,\n",
       "             'laugh': 105,\n",
       "             'place': 106,\n",
       "             'effect': 107,\n",
       "             'reason': 108,\n",
       "             'tv': 109,\n",
       "             'probably': 110,\n",
       "             'hard': 111,\n",
       "             'screen': 112,\n",
       "             'book': 113,\n",
       "             'child': 114,\n",
       "             'away': 115,\n",
       "             'let': 116,\n",
       "             'moment': 117,\n",
       "             'help': 118,\n",
       "             'have': 119,\n",
       "             'read': 120,\n",
       "             'fun': 121,\n",
       "             'audience': 122,\n",
       "             'sure': 123,\n",
       "             'idea': 124,\n",
       "             'high': 125,\n",
       "             'war': 126,\n",
       "             'episode': 127,\n",
       "             'expect': 128,\n",
       "             'especially': 129,\n",
       "             'dvd': 130,\n",
       "             'fall': 131,\n",
       "             'course': 132,\n",
       "             'bring': 133,\n",
       "             'job': 134,\n",
       "             'sense': 135,\n",
       "             'different': 136,\n",
       "             'use': 137,\n",
       "             'worth': 138,\n",
       "             'main': 139,\n",
       "             'sound': 140,\n",
       "             'maybe': 141,\n",
       "             'bore': 142,\n",
       "             'mind': 143,\n",
       "             'boy': 144,\n",
       "             'american': 145,\n",
       "             'direct': 146,\n",
       "             'lose': 147,\n",
       "             'true': 148,\n",
       "             'problem': 149,\n",
       "             'money': 150,\n",
       "             'hope': 151,\n",
       "             'version': 152,\n",
       "             'face': 153,\n",
       "             'early': 154,\n",
       "             'recommend': 155,\n",
       "             'understand': 156,\n",
       "             'night': 157,\n",
       "             'follow': 158,\n",
       "             'short': 159,\n",
       "             'house': 160,\n",
       "             'black': 161,\n",
       "             'talk': 162,\n",
       "             'waste': 163,\n",
       "             'special': 164,\n",
       "             'wife': 165,\n",
       "             'instead': 166,\n",
       "             'fight': 167,\n",
       "             'half': 168,\n",
       "             'low': 169,\n",
       "             'eye': 170,\n",
       "             'miss': 171,\n",
       "             'hear': 172,\n",
       "             'open': 173,\n",
       "             'head': 174,\n",
       "             'beautiful': 175,\n",
       "             'john': 176,\n",
       "             'view': 177,\n",
       "             'hour': 178,\n",
       "             'death': 179,\n",
       "             'excellent': 180,\n",
       "             'father': 181,\n",
       "             'hand': 182,\n",
       "             'change': 183,\n",
       "             'classic': 184,\n",
       "             'budget': 185,\n",
       "             'include': 186,\n",
       "             'piece': 187,\n",
       "             'remember': 188,\n",
       "             'call': 189,\n",
       "             'viewer': 190,\n",
       "             'rate': 191,\n",
       "             'surprise': 192,\n",
       "             'appear': 193,\n",
       "             'nice': 194,\n",
       "             'simply': 195,\n",
       "             'release': 196,\n",
       "             'production': 197,\n",
       "             'poor': 198,\n",
       "             'completely': 199,\n",
       "             'camera': 200,\n",
       "             'couple': 201,\n",
       "             'attempt': 202,\n",
       "             'feature': 203,\n",
       "             'yes': 204,\n",
       "             'home': 205,\n",
       "             'human': 206,\n",
       "             'video': 207,\n",
       "             'lack': 208,\n",
       "             'picture': 209,\n",
       "             '2': 210,\n",
       "             'involve': 211,\n",
       "             'word': 212,\n",
       "             'song': 213,\n",
       "             'dead': 214,\n",
       "             'meet': 215,\n",
       "             'school': 216,\n",
       "             'care': 217,\n",
       "             'suppose': 218,\n",
       "             'close': 219,\n",
       "             'hollywood': 220,\n",
       "             'entertain': 221,\n",
       "             'rest': 222,\n",
       "             'add': 223,\n",
       "             'stupid': 224,\n",
       "             'decide': 225,\n",
       "             'sex': 226,\n",
       "             'person': 227,\n",
       "             'writer': 228,\n",
       "             'small': 229,\n",
       "             'die': 230,\n",
       "             'style': 231,\n",
       "             'sort': 232,\n",
       "             'murder': 233,\n",
       "             'truly': 234,\n",
       "             'save': 235,\n",
       "             'move': 236,\n",
       "             'keep': 237,\n",
       "             'title': 238,\n",
       "             'game': 239,\n",
       "             'light': 240,\n",
       "             'awful': 241,\n",
       "             'create': 242,\n",
       "             'okay': 243,\n",
       "             'will': 244,\n",
       "             'dialogue': 245,\n",
       "             'wonder': 246,\n",
       "             'mother': 247,\n",
       "             'review': 248,\n",
       "             'case': 249,\n",
       "             'wonderful': 250,\n",
       "             'stop': 251,\n",
       "             'terrible': 252,\n",
       "             'perfect': 253,\n",
       "             'flick': 254,\n",
       "             'guess': 255,\n",
       "             'base': 256,\n",
       "             'definitely': 257,\n",
       "             'age': 258,\n",
       "             'joke': 259,\n",
       "             'sequence': 260,\n",
       "             'stand': 261,\n",
       "             'brother': 262,\n",
       "             'comment': 263,\n",
       "             'art': 264,\n",
       "             'example': 265,\n",
       "             'sit': 266,\n",
       "             'fine': 267,\n",
       "             'cut': 268,\n",
       "             'actress': 269,\n",
       "             'mention': 270,\n",
       "             'killer': 271,\n",
       "             'consider': 272,\n",
       "             'dark': 273,\n",
       "             'force': 274,\n",
       "             'drama': 275,\n",
       "             'experience': 276,\n",
       "             'absolutely': 277,\n",
       "             'certainly': 278,\n",
       "             'ask': 279,\n",
       "             'car': 280,\n",
       "             'amaze': 281,\n",
       "             'quality': 282,\n",
       "             'buy': 283,\n",
       "             'son': 284,\n",
       "             'hit': 285,\n",
       "             'break': 286,\n",
       "             'deal': 287,\n",
       "             'entire': 288,\n",
       "             'cinema': 289,\n",
       "             'hold': 290,\n",
       "             'direction': 291,\n",
       "             'white': 292,\n",
       "             'learn': 293,\n",
       "             'matt': 294,\n",
       "             'voice': 295,\n",
       "             'evil': 296,\n",
       "             'oh': 297,\n",
       "             'fail': 298,\n",
       "             'heart': 299,\n",
       "             'type': 300,\n",
       "             'spend': 301,\n",
       "             'finally': 302,\n",
       "             'totally': 303,\n",
       "             'disappoint': 304,\n",
       "             'hero': 305,\n",
       "             'favorite': 306,\n",
       "             'wait': 307,\n",
       "             'win': 308,\n",
       "             'humor': 309,\n",
       "             'speak': 310,\n",
       "             'dance': 311,\n",
       "             'mr': 312,\n",
       "             'relationship': 313,\n",
       "             'forget': 314,\n",
       "             'support': 315,\n",
       "             'able': 316,\n",
       "             'throw': 317,\n",
       "             'walk': 318,\n",
       "             'daughter': 319,\n",
       "             'final': 320,\n",
       "             'group': 321,\n",
       "             'manage': 322,\n",
       "             'twist': 323,\n",
       "             'stay': 324,\n",
       "             'present': 325,\n",
       "             '\\x96': 326,\n",
       "             'portray': 327,\n",
       "             'genre': 328,\n",
       "             'god': 329,\n",
       "             'wish': 330,\n",
       "             'despite': 331,\n",
       "             'town': 332,\n",
       "             'pay': 333,\n",
       "             'today': 334,\n",
       "             'hate': 335,\n",
       "             'credit': 336,\n",
       "             'strong': 337,\n",
       "             'score': 338,\n",
       "             'stuff': 339,\n",
       "             'horrible': 340,\n",
       "             'soon': 341,\n",
       "             'realize': 342,\n",
       "             'name': 343,\n",
       "             'part': 344,\n",
       "             'history': 345,\n",
       "             'talent': 346,\n",
       "             'city': 347,\n",
       "             'touch': 348,\n",
       "             'deserve': 349,\n",
       "             'catch': 350,\n",
       "             'power': 351,\n",
       "             'question': 352,\n",
       "             'past': 353,\n",
       "             'body': 354,\n",
       "             'slow': 355,\n",
       "             'drive': 356,\n",
       "             'unfortunately': 357,\n",
       "             'event': 358,\n",
       "             'theme': 359,\n",
       "             'overall': 360,\n",
       "             'michael': 361,\n",
       "             'return': 362,\n",
       "             'order': 363,\n",
       "             'chance': 364,\n",
       "             'obviously': 365,\n",
       "             'blood': 366,\n",
       "             'etc': 367,\n",
       "             'situation': 368,\n",
       "             'level': 369,\n",
       "             'brilliant': 370,\n",
       "             'self': 371,\n",
       "             'highly': 372,\n",
       "             'grow': 373,\n",
       "             'annoy': 374,\n",
       "             'pace': 375,\n",
       "             'decent': 376,\n",
       "             'edit': 377,\n",
       "             'pick': 378,\n",
       "             'cool': 379,\n",
       "             'complete': 380,\n",
       "             'figure': 381,\n",
       "             'country': 382,\n",
       "             'documentary': 383,\n",
       "             'novel': 384,\n",
       "             'element': 385,\n",
       "             'build': 386,\n",
       "             'extremely': 387,\n",
       "             'simple': 388,\n",
       "             'sister': 389,\n",
       "             'monster': 390,\n",
       "             'police': 391,\n",
       "             'numb': 392,\n",
       "             'musical': 393,\n",
       "             'strange': 394,\n",
       "             'career': 395,\n",
       "             'dream': 396,\n",
       "             'reality': 397,\n",
       "             'provide': 398,\n",
       "             'particularly': 399,\n",
       "             'violence': 400,\n",
       "             'state': 401,\n",
       "             'opinion': 402,\n",
       "             'deliver': 403,\n",
       "             'female': 404,\n",
       "             'husband': 405,\n",
       "             'scary': 406,\n",
       "             'zombie': 407,\n",
       "             'theater': 408,\n",
       "             'hell': 409,\n",
       "             'hilarious': 410,\n",
       "             'cause': 411,\n",
       "             'gore': 412,\n",
       "             'room': 413,\n",
       "             'cop': 414,\n",
       "             'lady': 415,\n",
       "             'effort': 416,\n",
       "             'explain': 417,\n",
       "             'result': 418,\n",
       "             'james': 419,\n",
       "             'class': 420,\n",
       "             'david': 421,\n",
       "             'english': 422,\n",
       "             'sequel': 423,\n",
       "             'offer': 424,\n",
       "             'allow': 425,\n",
       "             'usually': 426,\n",
       "             'comic': 427,\n",
       "             'thriller': 428,\n",
       "             'obvious': 429,\n",
       "             'exactly': 430,\n",
       "             'crap': 431,\n",
       "             'sad': 432,\n",
       "             'focus': 433,\n",
       "             'robert': 434,\n",
       "             'ago': 435,\n",
       "             'dog': 436,\n",
       "             'shot': 437,\n",
       "             'check': 438,\n",
       "             'draw': 439,\n",
       "             'value': 440,\n",
       "             'compare': 441,\n",
       "             'shock': 442,\n",
       "             'major': 443,\n",
       "             'seriously': 444,\n",
       "             'convince': 445,\n",
       "             'stick': 446,\n",
       "             'middle': 447,\n",
       "             'bear': 448,\n",
       "             'cover': 449,\n",
       "             'team': 450,\n",
       "             'b': 451,\n",
       "             'happy': 452,\n",
       "             'huge': 453,\n",
       "             'dialog': 454,\n",
       "             'subject': 455,\n",
       "             'note': 456,\n",
       "             'important': 457,\n",
       "             'silly': 458,\n",
       "             'fast': 459,\n",
       "             'produce': 460,\n",
       "             'attention': 461,\n",
       "             'steal': 462,\n",
       "             'form': 463,\n",
       "             'usual': 464,\n",
       "             'cinematography': 465,\n",
       "             'local': 466,\n",
       "             'ridiculous': 467,\n",
       "             'single': 468,\n",
       "             'rock': 469,\n",
       "             'possible': 470,\n",
       "             'producer': 471,\n",
       "             'detail': 472,\n",
       "             'message': 473,\n",
       "             'cheap': 474,\n",
       "             'easy': 475,\n",
       "             'season': 476,\n",
       "             'one': 477,\n",
       "             'tale': 478,\n",
       "             'pass': 479,\n",
       "             'deep': 480,\n",
       "             'pull': 481,\n",
       "             'non': 482,\n",
       "             'drug': 483,\n",
       "             'somewhat': 484,\n",
       "             'parent': 485,\n",
       "             'near': 486,\n",
       "             'modern': 487,\n",
       "             'train': 488,\n",
       "             'fill': 489,\n",
       "             'prove': 490,\n",
       "             'television': 491,\n",
       "             'image': 492,\n",
       "             'clearly': 493,\n",
       "             'apparently': 494,\n",
       "             'wear': 495,\n",
       "             'charm': 496,\n",
       "             'air': 497,\n",
       "             'remain': 498,\n",
       "             'king': 499,\n",
       "             'discover': 500,\n",
       "             'space': 501,\n",
       "             'gun': 502,\n",
       "             'street': 503,\n",
       "             'avoid': 504,\n",
       "             'clear': 505,\n",
       "             'imagine': 506,\n",
       "             'escape': 507,\n",
       "             'member': 508,\n",
       "             'doubt': 509,\n",
       "             'stage': 510,\n",
       "             'villain': 511,\n",
       "             'basically': 512,\n",
       "             'jack': 513,\n",
       "             'capture': 514,\n",
       "             'date': 515,\n",
       "             'marry': 516,\n",
       "             'western': 517,\n",
       "             'earth': 518,\n",
       "             'remind': 519,\n",
       "             'mystery': 520,\n",
       "             'soldier': 521,\n",
       "             'weak': 522,\n",
       "             'fire': 523,\n",
       "             'fit': 524,\n",
       "             'plan': 525,\n",
       "             'straight': 526,\n",
       "             'crime': 527,\n",
       "             'entertainment': 528,\n",
       "             'romantic': 529,\n",
       "             'british': 530,\n",
       "             'aspect': 531,\n",
       "             'predictable': 532,\n",
       "             'soundtrack': 533,\n",
       "             'box': 534,\n",
       "             'future': 535,\n",
       "             'french': 536,\n",
       "             'easily': 537,\n",
       "             'dull': 538,\n",
       "             'send': 539,\n",
       "             'peter': 540,\n",
       "             'enjoyable': 541,\n",
       "             'copy': 542,\n",
       "             'thank': 543,\n",
       "             'george': 544,\n",
       "             'carry': 545,\n",
       "             'bunch': 546,\n",
       "             'battle': 547,\n",
       "             'certain': 548,\n",
       "             'chase': 549,\n",
       "             'similar': 550,\n",
       "             'agree': 551,\n",
       "             'doctor': 552,\n",
       "             'confuse': 553,\n",
       "             'suck': 554,\n",
       "             'adult': 555,\n",
       "             'choose': 556,\n",
       "             'attack': 557,\n",
       "             'mark': 558,\n",
       "             'student': 559,\n",
       "             'general': 560,\n",
       "             'suspense': 561,\n",
       "             'emotion': 562,\n",
       "             'lie': 563,\n",
       "             'mess': 564,\n",
       "             'storyline': 565,\n",
       "             'animation': 566,\n",
       "             'typical': 567,\n",
       "             'water': 568,\n",
       "             'standard': 569,\n",
       "             'period': 570,\n",
       "             'victim': 571,\n",
       "             'visual': 572,\n",
       "             'contain': 573,\n",
       "             'cry': 574,\n",
       "             'eat': 575,\n",
       "             'actual': 576,\n",
       "             'material': 577,\n",
       "             'reveal': 578,\n",
       "             'notice': 579,\n",
       "             'rend': 580,\n",
       "             'mix': 581,\n",
       "             'famous': 582,\n",
       "             'fly': 583,\n",
       "             'sorry': 584,\n",
       "             'bill': 585,\n",
       "             'issue': 586,\n",
       "             'hide': 587,\n",
       "             'fantastic': 588,\n",
       "             'match': 589,\n",
       "             'trouble': 590,\n",
       "             'romance': 591,\n",
       "             'spoiler': 592,\n",
       "             'large': 593,\n",
       "             'red': 594,\n",
       "             'excite': 595,\n",
       "             'premise': 596,\n",
       "             'suffer': 597,\n",
       "             'oscar': 598,\n",
       "             'ride': 599,\n",
       "             'finish': 600,\n",
       "             'continue': 601,\n",
       "             'nearly': 602,\n",
       "             'beat': 603,\n",
       "             'hot': 604,\n",
       "             'admit': 605,\n",
       "             'vampire': 606,\n",
       "             'blow': 607,\n",
       "             'realistic': 608,\n",
       "             'dr': 609,\n",
       "             'male': 610,\n",
       "             'dumb': 611,\n",
       "             'believable': 612,\n",
       "             'describe': 613,\n",
       "             'lame': 614,\n",
       "             'list': 615,\n",
       "             'paul': 616,\n",
       "             'alien': 617,\n",
       "             'free': 618,\n",
       "             'forward': 619,\n",
       "             'richard': 620,\n",
       "             '$': 621,\n",
       "             'atmosphere': 622,\n",
       "             'fi': 623,\n",
       "             'party': 624,\n",
       "             'average': 625,\n",
       "             'truth': 626,\n",
       "             'sci': 627,\n",
       "             'appreciate': 628,\n",
       "             'cartoon': 629,\n",
       "             'crow': 630,\n",
       "             'america': 631,\n",
       "             'bother': 632,\n",
       "             'particular': 633,\n",
       "             'odd': 634,\n",
       "             'treat': 635,\n",
       "             'studio': 636,\n",
       "             'spirit': 637,\n",
       "             'background': 638,\n",
       "             'baby': 639,\n",
       "             'appeal': 640,\n",
       "             'remake': 641,\n",
       "             'wood': 642,\n",
       "             'gay': 643,\n",
       "             'scare': 644,\n",
       "             'possibly': 645,\n",
       "             'shame': 646,\n",
       "             'secret': 647,\n",
       "             'difficult': 648,\n",
       "             'emotional': 649,\n",
       "             'society': 650,\n",
       "             'tom': 651,\n",
       "             'weird': 652,\n",
       "             'beauty': 653,\n",
       "             'girlfriend': 654,\n",
       "             'drink': 655,\n",
       "             'master': 656,\n",
       "             'masterpiece': 657,\n",
       "             'footage': 658,\n",
       "             's': 659,\n",
       "             'poorly': 660,\n",
       "             'sexual': 661,\n",
       "             'mistake': 662,\n",
       "             'rich': 663,\n",
       "             'eventually': 664,\n",
       "             'york': 665,\n",
       "             'lover': 666,\n",
       "             'control': 667,\n",
       "             'award': 668,\n",
       "             'adventure': 669,\n",
       "             'de': 670,\n",
       "             'screenplay': 671,\n",
       "             'week': 672,\n",
       "             'fear': 673,\n",
       "             'choice': 674,\n",
       "             'cliché': 675,\n",
       "             'japanese': 676,\n",
       "             'costume': 677,\n",
       "             'lee': 678,\n",
       "             'crazy': 679,\n",
       "             'accent': 680,\n",
       "             'plus': 681,\n",
       "             'suggest': 682,\n",
       "             'inside': 683,\n",
       "             'struggle': 684,\n",
       "             'incredibly': 685,\n",
       "             'memorable': 686,\n",
       "             'imdb': 687,\n",
       "             'cheesy': 688,\n",
       "             'brain': 689,\n",
       "             'tear': 690,\n",
       "             'superb': 691,\n",
       "             'flaw': 692,\n",
       "             'animal': 693,\n",
       "             'respect': 694,\n",
       "             'development': 695,\n",
       "             'badly': 696,\n",
       "             'scream': 697,\n",
       "             'previous': 698,\n",
       "             'total': 699,\n",
       "             'perfectly': 700,\n",
       "             'jump': 701,\n",
       "             'track': 702,\n",
       "             'project': 703,\n",
       "             'location': 704,\n",
       "             'fantasy': 705,\n",
       "             'teen': 706,\n",
       "             'personal': 707,\n",
       "             'disney': 708,\n",
       "             'dramatic': 709,\n",
       "             'rise': 710,\n",
       "             'nature': 711,\n",
       "             'quickly': 712,\n",
       "             'warn': 713,\n",
       "             'maker': 714,\n",
       "             'business': 715,\n",
       "             'company': 716,\n",
       "             'answer': 717,\n",
       "             'creepy': 718,\n",
       "             'color': 719,\n",
       "             'sell': 720,\n",
       "             'term': 721,\n",
       "             'dress': 722,\n",
       "             'island': 723,\n",
       "             'joe': 724,\n",
       "             'plenty': 725,\n",
       "             'land': 726,\n",
       "             'disturb': 727,\n",
       "             'store': 728,\n",
       "             'cute': 729,\n",
       "             'political': 730,\n",
       "             'fairly': 731,\n",
       "             'powerful': 732,\n",
       "             'serve': 733,\n",
       "             '`': 734,\n",
       "             'concern': 735,\n",
       "             'promise': 736,\n",
       "             'unique': 737,\n",
       "             'post': 738,\n",
       "             'plain': 739,\n",
       "             'rip': 740,\n",
       "             'outside': 741,\n",
       "             'amuse': 742,\n",
       "             'office': 743,\n",
       "             'law': 744,\n",
       "             'clever': 745,\n",
       "             'destroy': 746,\n",
       "             'portrayal': 747,\n",
       "             'design': 748,\n",
       "             'century': 749,\n",
       "             'appearance': 750,\n",
       "             'accept': 751,\n",
       "             'channel': 752,\n",
       "             'depth': 753,\n",
       "             'success': 754,\n",
       "             'blue': 755,\n",
       "             'william': 756,\n",
       "             'hole': 757,\n",
       "             'roll': 758,\n",
       "             'era': 759,\n",
       "             'inspire': 760,\n",
       "             'perform': 761,\n",
       "             'cat': 762,\n",
       "             'exist': 763,\n",
       "             'concept': 764,\n",
       "             'ability': 765,\n",
       "             'kick': 766,\n",
       "             'recently': 767,\n",
       "             'talented': 768,\n",
       "             'creature': 769,\n",
       "             'player': 770,\n",
       "             'band': 771,\n",
       "             'memory': 772,\n",
       "             'share': 773,\n",
       "             'ghost': 774,\n",
       "             'step': 775,\n",
       "             'sleep': 776,\n",
       "             'familiar': 777,\n",
       "             'cold': 778,\n",
       "             'pop': 779,\n",
       "             'spot': 780,\n",
       "             'soul': 781,\n",
       "             'filmmakers': 782,\n",
       "             'flat': 783,\n",
       "             'german': 784,\n",
       "             'culture': 785,\n",
       "             'door': 786,\n",
       "             'listen': 787,\n",
       "             'travel': 788,\n",
       "             'apart': 789,\n",
       "             'sing': 790,\n",
       "             'record': 791,\n",
       "             'reach': 792,\n",
       "             'camp': 793,\n",
       "             'hardly': 794,\n",
       "             'burn': 795,\n",
       "             'science': 796,\n",
       "             'jane': 797,\n",
       "             'tension': 798,\n",
       "             'pure': 799,\n",
       "             'van': 800,\n",
       "             'sweet': 801,\n",
       "             'incredible': 802,\n",
       "             'introduce': 803,\n",
       "             'claim': 804,\n",
       "             'public': 805,\n",
       "             'extra': 806,\n",
       "             'relate': 807,\n",
       "             'la': 808,\n",
       "             'nudity': 809,\n",
       "             'gang': 810,\n",
       "             'search': 811,\n",
       "             'potential': 812,\n",
       "             'italian': 813,\n",
       "             'receive': 814,\n",
       "             'language': 815,\n",
       "             'tone': 816,\n",
       "             'drag': 817,\n",
       "             'strike': 818,\n",
       "             'not': 819,\n",
       "             'rent': 820,\n",
       "             'slightly': 821,\n",
       "             'co': 822,\n",
       "             'intrigue': 823,\n",
       "             'park': 824,\n",
       "             'race': 825,\n",
       "             'approach': 826,\n",
       "             'suit': 827,\n",
       "             'unlike': 828,\n",
       "             'hang': 829,\n",
       "             'wind': 830,\n",
       "             'ruin': 831,\n",
       "             'count': 832,\n",
       "             'common': 833,\n",
       "             'ring': 834,\n",
       "             'edge': 835,\n",
       "             'drop': 836,\n",
       "             'college': 837,\n",
       "             'hair': 838,\n",
       "             'taste': 839,\n",
       "             'engage': 840,\n",
       "             'rape': 841,\n",
       "             'entirely': 842,\n",
       "             'mad': 843,\n",
       "             'basic': 844,\n",
       "             'popular': 845,\n",
       "             'intelligent': 846,\n",
       "             'smart': 847,\n",
       "             'sick': 848,\n",
       "             'fake': 849,\n",
       "             'bond': 850,\n",
       "             'social': 851,\n",
       "             'bizarre': 852,\n",
       "             'suddenly': 853,\n",
       "             'anti': 854,\n",
       "             'fashion': 855,\n",
       "             'clothe': 856,\n",
       "             'scott': 857,\n",
       "             'trip': 858,\n",
       "             'positive': 859,\n",
       "             'wild': 860,\n",
       "             'critic': 861,\n",
       "             'purpose': 862,\n",
       "             'computer': 863,\n",
       "             'handle': 864,\n",
       "             'ship': 865,\n",
       "             'successful': 866,\n",
       "             'alive': 867,\n",
       "             'adaptation': 868,\n",
       "             'ben': 869,\n",
       "             'survive': 870,\n",
       "             'road': 871,\n",
       "             'fiction': 872,\n",
       "             'judge': 873,\n",
       "             'super': 874,\n",
       "             'scientist': 875,\n",
       "             'fascinate': 876,\n",
       "             'visit': 877,\n",
       "             'torture': 878,\n",
       "             'teenager': 879,\n",
       "             'prison': 880,\n",
       "             'christmas': 881,\n",
       "             'develope': 882,\n",
       "             'violent': 883,\n",
       "             'tough': 884,\n",
       "             'impressive': 885,\n",
       "             'sadly': 886,\n",
       "             'genius': 887,\n",
       "             'hurt': 888,\n",
       "             'raise': 889,\n",
       "             'army': 890,\n",
       "             'barely': 891,\n",
       "             'wall': 892,\n",
       "             'awesome': 893,\n",
       "             'fair': 894,\n",
       "             'rule': 895,\n",
       "             'difference': 896,\n",
       "             'personality': 897,\n",
       "             'humour': 898,\n",
       "             'suspect': 899,\n",
       "             'reference': 900,\n",
       "             'pointless': 901,\n",
       "             'cross': 902,\n",
       "             'reviewer': 903,\n",
       "             'planet': 904,\n",
       "             'seek': 905,\n",
       "             'giant': 906,\n",
       "             'club': 907,\n",
       "             'artist': 908,\n",
       "             'animate': 909,\n",
       "             'slasher': 910,\n",
       "             'honest': 911,\n",
       "             'conclusion': 912,\n",
       "             'recent': 913,\n",
       "             'sign': 914,\n",
       "             'solid': 915,\n",
       "             'impress': 916,\n",
       "             'intend': 917,\n",
       "             'folk': 918,\n",
       "             'bar': 919,\n",
       "             'trash': 920,\n",
       "             'government': 921,\n",
       "             'aside': 922,\n",
       "             'heavy': 923,\n",
       "             'mood': 924,\n",
       "             'normal': 925,\n",
       "             'compel': 926,\n",
       "             'ultimately': 927,\n",
       "             'revenge': 928,\n",
       "             'cult': 929,\n",
       "             'singe': 930,\n",
       "             'charles': 931,\n",
       "             'effective': 932,\n",
       "             'study': 933,\n",
       "             'detective': 934,\n",
       "             'motion': 935,\n",
       "             'haunt': 936,\n",
       "             'journey': 937,\n",
       "             'pathetic': 938,\n",
       "             'excuse': 939,\n",
       "             'arrive': 940,\n",
       "             'trailer': 941,\n",
       "             'frank': 942,\n",
       "             'foot': 943,\n",
       "             'tire': 944,\n",
       "             'cost': 945,\n",
       "             'stun': 946,\n",
       "             'chemistry': 947,\n",
       "             'sexy': 948,\n",
       "             'impossible': 949,\n",
       "             'surprisingly': 950,\n",
       "             'machine': 951,\n",
       "             'jim': 952,\n",
       "             'south': 953,\n",
       "             'enter': 954,\n",
       "             'bed': 955,\n",
       "             'limit': 956,\n",
       "             'horse': 957,\n",
       "             'literally': 958,\n",
       "             'interview': 959,\n",
       "             'agent': 960,\n",
       "             'dad': 961,\n",
       "             'opportunity': 962,\n",
       "             'steve': 963,\n",
       "             'immediately': 964,\n",
       "             'ray': 965,\n",
       "             'affair': 966,\n",
       "             'garbage': 967,\n",
       "             'pain': 968,\n",
       "             'arm': 969,\n",
       "             'grade': 970,\n",
       "             'glad': 971,\n",
       "             'plane': 972,\n",
       "             'opus': 973,\n",
       "             'ex': 974,\n",
       "             'honestly': 975,\n",
       "             'mouth': 976,\n",
       "             'repeat': 977,\n",
       "             'key': 978,\n",
       "             'military': 979,\n",
       "             'naked': 980,\n",
       "             'display': 981,\n",
       "             'generally': 982,\n",
       "             'sam': 983,\n",
       "             'jones': 984,\n",
       "             'festival': 985,\n",
       "             'innocent': 986,\n",
       "             'commit': 987,\n",
       "             'smile': 988,\n",
       "             'mary': 989,\n",
       "             'silent': 990,\n",
       "             'paint': 991,\n",
       "             'moral': 992,\n",
       "             'criminal': 993,\n",
       "             'stereotype': 994,\n",
       "             'boyfriend': 995,\n",
       "             'subtle': 996,\n",
       "             'complex': 997,\n",
       "             'impression': 998,\n",
       "             'london': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display word2index dictionary\n",
    "train_vocab.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 281,    8,  250,    5,  154, 2455,  373,  509, 1076, 1197,  796,\n",
       "        872,  328,   84,  261, 2533, 2533,   64, 1650,  499,  203,    5,\n",
       "         94,   11, 2281,  979,  796,  381, 1125,  788,  904, 4835,  979,\n",
       "         71,  392,  450, 1167,  450,  174,  979, 1497, 2958,  513,  186,\n",
       "        552, 2174, 1275,  979,  875, 1232, 4316, 2778,  617, 3143, 1233,\n",
       "        151,   72,  618,   20,  518,  712,   32, 1180,  825,  137,  206,\n",
       "       1566,   13, 2027, 1815,   57,  133,   40,  620, 1795, 1854,  253,\n",
       "       2369, 4904, 2233, 1954, 4836,  170,  361, 2174,  133,  299, 3461,\n",
       "          9,  373, 1228,  170, 2424,  273,  111,   89, 1592, 3248, 2554,\n",
       "       2778,  253, 1541, 1012,    9, 4948,   76,  337,  846,  979,  875,\n",
       "       1181,  873,  180,  316, 1012,    9,  562, 2586, 1264,  659, 1529,\n",
       "          2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depict the first dataset sequence\n",
    "train_vocab.dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation set\n",
    "val_dataset = pd.read_csv('dataset/datasets_feat_clean/val_feat_clean.csv', \n",
    "                      usecols=['clean_review', 'polarity', 'word_count','label'],\n",
    "                      dtype={'clean_review': str, 'label': np.int16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the columns order\n",
    "val_dataset = val_dataset[['clean_review', 'polarity', 'word_count', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_review</th>\n",
       "      <th>polarity</th>\n",
       "      <th>word_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>go movie twice week sum word normally use ligh...</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>year big fan park work old boy time favorite.w...</td>\n",
       "      <td>-0.056670</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>movie potential handle differently need differ...</td>\n",
       "      <td>-0.012695</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>movie difficult review give away plot suffice ...</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>plot worth discussion hint corruption murder p...</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        clean_review  polarity  word_count  \\\n",
       "0  go movie twice week sum word normally use ligh...  0.272000         155   \n",
       "1  year big fan park work old boy time favorite.w... -0.056670         119   \n",
       "2  movie potential handle differently need differ... -0.012695         152   \n",
       "3  movie difficult review give away plot suffice ...  0.148400         173   \n",
       "4  plot worth discussion hint corruption murder p...  0.215300         105   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows from the dataset\n",
    "val_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed vocabulary using maximum size of: 5000\n",
      "5000/59089 tokens has been retained\n",
      "Trimmed input strings vocabulary\n",
      "Trimmed input sequences lengths to the length of: 119\n",
      "Mapped words to indices\n"
     ]
    }
   ],
   "source": [
    "val_vocab = Vocab(val_dataset, target_col=None, word2index=train_vocab.word2index, sos_token='<SOS>', eos_token='<EOS>',\n",
    "                  unk_token='<UNK>', pad_token='<PAD>', min_word_count=None, max_vocab_size=5000, max_seq_len=0.8,\n",
    "                  use_pretrained_vectors=False, glove_path='Glove/', glove_name='glove.6B.100d.txt',\n",
    "                  weights_file_name='Glove/weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Vocab.mapWord2index.<locals>.<lambda>()>,\n",
       "            {'<PAD>': 0,\n",
       "             '<SOS>': 1,\n",
       "             '<EOS>': 2,\n",
       "             '<UNK>': 3,\n",
       "             'movie': 4,\n",
       "             'film': 5,\n",
       "             'like': 6,\n",
       "             'time': 7,\n",
       "             'good': 8,\n",
       "             'character': 9,\n",
       "             'watch': 10,\n",
       "             'see': 11,\n",
       "             'story': 12,\n",
       "             'think': 13,\n",
       "             'well': 14,\n",
       "             'scene': 15,\n",
       "             'great': 16,\n",
       "             'look': 17,\n",
       "             'know': 18,\n",
       "             'end': 19,\n",
       "             'people': 20,\n",
       "             'go': 21,\n",
       "             'bad': 22,\n",
       "             'get': 23,\n",
       "             'love': 24,\n",
       "             'act': 25,\n",
       "             'play': 26,\n",
       "             'way': 27,\n",
       "             'come': 28,\n",
       "             'thing': 29,\n",
       "             'find': 30,\n",
       "             'man': 31,\n",
       "             'make': 32,\n",
       "             'plot': 33,\n",
       "             'work': 34,\n",
       "             'actor': 35,\n",
       "             'want': 36,\n",
       "             'year': 37,\n",
       "             'little': 38,\n",
       "             'feel': 39,\n",
       "             'life': 40,\n",
       "             'try': 41,\n",
       "             'wrong': 42,\n",
       "             'give': 43,\n",
       "             'old': 44,\n",
       "             'take': 45,\n",
       "             'director': 46,\n",
       "             'lot': 47,\n",
       "             'interest': 48,\n",
       "             'funny': 49,\n",
       "             'real': 50,\n",
       "             'show': 51,\n",
       "             'guy': 52,\n",
       "             'woman': 53,\n",
       "             'performance': 54,\n",
       "             'leave': 55,\n",
       "             'say': 56,\n",
       "             'cast': 57,\n",
       "             'big': 58,\n",
       "             'live': 59,\n",
       "             'actually': 60,\n",
       "             'tell': 61,\n",
       "             'young': 62,\n",
       "             'new': 63,\n",
       "             'star': 64,\n",
       "             'start': 65,\n",
       "             'role': 66,\n",
       "             'long': 67,\n",
       "             'write': 68,\n",
       "             'point': 69,\n",
       "             'girl': 70,\n",
       "             'set': 71,\n",
       "             'day': 72,\n",
       "             'world': 73,\n",
       "             'turn': 74,\n",
       "             'horror': 75,\n",
       "             'fact': 76,\n",
       "             'pretty': 77,\n",
       "             'comedy': 78,\n",
       "             'kill': 79,\n",
       "             'action': 80,\n",
       "             'minute': 81,\n",
       "             'happen': 82,\n",
       "             'late': 83,\n",
       "             'right': 84,\n",
       "             'mean': 85,\n",
       "             'line': 86,\n",
       "             'need': 87,\n",
       "             'fan': 88,\n",
       "             'bite': 89,\n",
       "             'enjoy': 90,\n",
       "             'friend': 91,\n",
       "             'music': 92,\n",
       "             'script': 93,\n",
       "             'series': 94,\n",
       "             'original': 95,\n",
       "             'family': 96,\n",
       "             'begin': 97,\n",
       "             'kid': 98,\n",
       "             'believe': 99,\n",
       "             'shoot': 100,\n",
       "             'lead': 101,\n",
       "             'far': 102,\n",
       "             'kind': 103,\n",
       "             'run': 104,\n",
       "             'laugh': 105,\n",
       "             'place': 106,\n",
       "             'effect': 107,\n",
       "             'reason': 108,\n",
       "             'tv': 109,\n",
       "             'probably': 110,\n",
       "             'hard': 111,\n",
       "             'screen': 112,\n",
       "             'book': 113,\n",
       "             'child': 114,\n",
       "             'away': 115,\n",
       "             'let': 116,\n",
       "             'moment': 117,\n",
       "             'help': 118,\n",
       "             'have': 119,\n",
       "             'read': 120,\n",
       "             'fun': 121,\n",
       "             'audience': 122,\n",
       "             'sure': 123,\n",
       "             'idea': 124,\n",
       "             'high': 125,\n",
       "             'war': 126,\n",
       "             'episode': 127,\n",
       "             'expect': 128,\n",
       "             'especially': 129,\n",
       "             'dvd': 130,\n",
       "             'fall': 131,\n",
       "             'course': 132,\n",
       "             'bring': 133,\n",
       "             'job': 134,\n",
       "             'sense': 135,\n",
       "             'different': 136,\n",
       "             'use': 137,\n",
       "             'worth': 138,\n",
       "             'main': 139,\n",
       "             'sound': 140,\n",
       "             'maybe': 141,\n",
       "             'bore': 142,\n",
       "             'mind': 143,\n",
       "             'boy': 144,\n",
       "             'american': 145,\n",
       "             'direct': 146,\n",
       "             'lose': 147,\n",
       "             'true': 148,\n",
       "             'problem': 149,\n",
       "             'money': 150,\n",
       "             'hope': 151,\n",
       "             'version': 152,\n",
       "             'face': 153,\n",
       "             'early': 154,\n",
       "             'recommend': 155,\n",
       "             'understand': 156,\n",
       "             'night': 157,\n",
       "             'follow': 158,\n",
       "             'short': 159,\n",
       "             'house': 160,\n",
       "             'black': 161,\n",
       "             'talk': 162,\n",
       "             'waste': 163,\n",
       "             'special': 164,\n",
       "             'wife': 165,\n",
       "             'instead': 166,\n",
       "             'fight': 167,\n",
       "             'half': 168,\n",
       "             'low': 169,\n",
       "             'eye': 170,\n",
       "             'miss': 171,\n",
       "             'hear': 172,\n",
       "             'open': 173,\n",
       "             'head': 174,\n",
       "             'beautiful': 175,\n",
       "             'john': 176,\n",
       "             'view': 177,\n",
       "             'hour': 178,\n",
       "             'death': 179,\n",
       "             'excellent': 180,\n",
       "             'father': 181,\n",
       "             'hand': 182,\n",
       "             'change': 183,\n",
       "             'classic': 184,\n",
       "             'budget': 185,\n",
       "             'include': 186,\n",
       "             'piece': 187,\n",
       "             'remember': 188,\n",
       "             'call': 189,\n",
       "             'viewer': 190,\n",
       "             'rate': 191,\n",
       "             'surprise': 192,\n",
       "             'appear': 193,\n",
       "             'nice': 194,\n",
       "             'simply': 195,\n",
       "             'release': 196,\n",
       "             'production': 197,\n",
       "             'poor': 198,\n",
       "             'completely': 199,\n",
       "             'camera': 200,\n",
       "             'couple': 201,\n",
       "             'attempt': 202,\n",
       "             'feature': 203,\n",
       "             'yes': 204,\n",
       "             'home': 205,\n",
       "             'human': 206,\n",
       "             'video': 207,\n",
       "             'lack': 208,\n",
       "             'picture': 209,\n",
       "             '2': 210,\n",
       "             'involve': 211,\n",
       "             'word': 212,\n",
       "             'song': 213,\n",
       "             'dead': 214,\n",
       "             'meet': 215,\n",
       "             'school': 216,\n",
       "             'care': 217,\n",
       "             'suppose': 218,\n",
       "             'close': 219,\n",
       "             'hollywood': 220,\n",
       "             'entertain': 221,\n",
       "             'rest': 222,\n",
       "             'add': 223,\n",
       "             'stupid': 224,\n",
       "             'decide': 225,\n",
       "             'sex': 226,\n",
       "             'person': 227,\n",
       "             'writer': 228,\n",
       "             'small': 229,\n",
       "             'die': 230,\n",
       "             'style': 231,\n",
       "             'sort': 232,\n",
       "             'murder': 233,\n",
       "             'truly': 234,\n",
       "             'save': 235,\n",
       "             'move': 236,\n",
       "             'keep': 237,\n",
       "             'title': 238,\n",
       "             'game': 239,\n",
       "             'light': 240,\n",
       "             'awful': 241,\n",
       "             'create': 242,\n",
       "             'okay': 243,\n",
       "             'will': 244,\n",
       "             'dialogue': 245,\n",
       "             'wonder': 246,\n",
       "             'mother': 247,\n",
       "             'review': 248,\n",
       "             'case': 249,\n",
       "             'wonderful': 250,\n",
       "             'stop': 251,\n",
       "             'terrible': 252,\n",
       "             'perfect': 253,\n",
       "             'flick': 254,\n",
       "             'guess': 255,\n",
       "             'base': 256,\n",
       "             'definitely': 257,\n",
       "             'age': 258,\n",
       "             'joke': 259,\n",
       "             'sequence': 260,\n",
       "             'stand': 261,\n",
       "             'brother': 262,\n",
       "             'comment': 263,\n",
       "             'art': 264,\n",
       "             'example': 265,\n",
       "             'sit': 266,\n",
       "             'fine': 267,\n",
       "             'cut': 268,\n",
       "             'actress': 269,\n",
       "             'mention': 270,\n",
       "             'killer': 271,\n",
       "             'consider': 272,\n",
       "             'dark': 273,\n",
       "             'force': 274,\n",
       "             'drama': 275,\n",
       "             'experience': 276,\n",
       "             'absolutely': 277,\n",
       "             'certainly': 278,\n",
       "             'ask': 279,\n",
       "             'car': 280,\n",
       "             'amaze': 281,\n",
       "             'quality': 282,\n",
       "             'buy': 283,\n",
       "             'son': 284,\n",
       "             'hit': 285,\n",
       "             'break': 286,\n",
       "             'deal': 287,\n",
       "             'entire': 288,\n",
       "             'cinema': 289,\n",
       "             'hold': 290,\n",
       "             'direction': 291,\n",
       "             'white': 292,\n",
       "             'learn': 293,\n",
       "             'matt': 294,\n",
       "             'voice': 295,\n",
       "             'evil': 296,\n",
       "             'oh': 297,\n",
       "             'fail': 298,\n",
       "             'heart': 299,\n",
       "             'type': 300,\n",
       "             'spend': 301,\n",
       "             'finally': 302,\n",
       "             'totally': 303,\n",
       "             'disappoint': 304,\n",
       "             'hero': 305,\n",
       "             'favorite': 306,\n",
       "             'wait': 307,\n",
       "             'win': 308,\n",
       "             'humor': 309,\n",
       "             'speak': 310,\n",
       "             'dance': 311,\n",
       "             'mr': 312,\n",
       "             'relationship': 313,\n",
       "             'forget': 314,\n",
       "             'support': 315,\n",
       "             'able': 316,\n",
       "             'throw': 317,\n",
       "             'walk': 318,\n",
       "             'daughter': 319,\n",
       "             'final': 320,\n",
       "             'group': 321,\n",
       "             'manage': 322,\n",
       "             'twist': 323,\n",
       "             'stay': 324,\n",
       "             'present': 325,\n",
       "             '\\x96': 326,\n",
       "             'portray': 327,\n",
       "             'genre': 328,\n",
       "             'god': 329,\n",
       "             'wish': 330,\n",
       "             'despite': 331,\n",
       "             'town': 332,\n",
       "             'pay': 333,\n",
       "             'today': 334,\n",
       "             'hate': 335,\n",
       "             'credit': 336,\n",
       "             'strong': 337,\n",
       "             'score': 338,\n",
       "             'stuff': 339,\n",
       "             'horrible': 340,\n",
       "             'soon': 341,\n",
       "             'realize': 342,\n",
       "             'name': 343,\n",
       "             'part': 344,\n",
       "             'history': 345,\n",
       "             'talent': 346,\n",
       "             'city': 347,\n",
       "             'touch': 348,\n",
       "             'deserve': 349,\n",
       "             'catch': 350,\n",
       "             'power': 351,\n",
       "             'question': 352,\n",
       "             'past': 353,\n",
       "             'body': 354,\n",
       "             'slow': 355,\n",
       "             'drive': 356,\n",
       "             'unfortunately': 357,\n",
       "             'event': 358,\n",
       "             'theme': 359,\n",
       "             'overall': 360,\n",
       "             'michael': 361,\n",
       "             'return': 362,\n",
       "             'order': 363,\n",
       "             'chance': 364,\n",
       "             'obviously': 365,\n",
       "             'blood': 366,\n",
       "             'etc': 367,\n",
       "             'situation': 368,\n",
       "             'level': 369,\n",
       "             'brilliant': 370,\n",
       "             'self': 371,\n",
       "             'highly': 372,\n",
       "             'grow': 373,\n",
       "             'annoy': 374,\n",
       "             'pace': 375,\n",
       "             'decent': 376,\n",
       "             'edit': 377,\n",
       "             'pick': 378,\n",
       "             'cool': 379,\n",
       "             'complete': 380,\n",
       "             'figure': 381,\n",
       "             'country': 382,\n",
       "             'documentary': 383,\n",
       "             'novel': 384,\n",
       "             'element': 385,\n",
       "             'build': 386,\n",
       "             'extremely': 387,\n",
       "             'simple': 388,\n",
       "             'sister': 389,\n",
       "             'monster': 390,\n",
       "             'police': 391,\n",
       "             'numb': 392,\n",
       "             'musical': 393,\n",
       "             'strange': 394,\n",
       "             'career': 395,\n",
       "             'dream': 396,\n",
       "             'reality': 397,\n",
       "             'provide': 398,\n",
       "             'particularly': 399,\n",
       "             'violence': 400,\n",
       "             'state': 401,\n",
       "             'opinion': 402,\n",
       "             'deliver': 403,\n",
       "             'female': 404,\n",
       "             'husband': 405,\n",
       "             'scary': 406,\n",
       "             'zombie': 407,\n",
       "             'theater': 408,\n",
       "             'hell': 409,\n",
       "             'hilarious': 410,\n",
       "             'cause': 411,\n",
       "             'gore': 412,\n",
       "             'room': 413,\n",
       "             'cop': 414,\n",
       "             'lady': 415,\n",
       "             'effort': 416,\n",
       "             'explain': 417,\n",
       "             'result': 418,\n",
       "             'james': 419,\n",
       "             'class': 420,\n",
       "             'david': 421,\n",
       "             'english': 422,\n",
       "             'sequel': 423,\n",
       "             'offer': 424,\n",
       "             'allow': 425,\n",
       "             'usually': 426,\n",
       "             'comic': 427,\n",
       "             'thriller': 428,\n",
       "             'obvious': 429,\n",
       "             'exactly': 430,\n",
       "             'crap': 431,\n",
       "             'sad': 432,\n",
       "             'focus': 433,\n",
       "             'robert': 434,\n",
       "             'ago': 435,\n",
       "             'dog': 436,\n",
       "             'shot': 437,\n",
       "             'check': 438,\n",
       "             'draw': 439,\n",
       "             'value': 440,\n",
       "             'compare': 441,\n",
       "             'shock': 442,\n",
       "             'major': 443,\n",
       "             'seriously': 444,\n",
       "             'convince': 445,\n",
       "             'stick': 446,\n",
       "             'middle': 447,\n",
       "             'bear': 448,\n",
       "             'cover': 449,\n",
       "             'team': 450,\n",
       "             'b': 451,\n",
       "             'happy': 452,\n",
       "             'huge': 453,\n",
       "             'dialog': 454,\n",
       "             'subject': 455,\n",
       "             'note': 456,\n",
       "             'important': 457,\n",
       "             'silly': 458,\n",
       "             'fast': 459,\n",
       "             'produce': 460,\n",
       "             'attention': 461,\n",
       "             'steal': 462,\n",
       "             'form': 463,\n",
       "             'usual': 464,\n",
       "             'cinematography': 465,\n",
       "             'local': 466,\n",
       "             'ridiculous': 467,\n",
       "             'single': 468,\n",
       "             'rock': 469,\n",
       "             'possible': 470,\n",
       "             'producer': 471,\n",
       "             'detail': 472,\n",
       "             'message': 473,\n",
       "             'cheap': 474,\n",
       "             'easy': 475,\n",
       "             'season': 476,\n",
       "             'one': 477,\n",
       "             'tale': 478,\n",
       "             'pass': 479,\n",
       "             'deep': 480,\n",
       "             'pull': 481,\n",
       "             'non': 482,\n",
       "             'drug': 483,\n",
       "             'somewhat': 484,\n",
       "             'parent': 485,\n",
       "             'near': 486,\n",
       "             'modern': 487,\n",
       "             'train': 488,\n",
       "             'fill': 489,\n",
       "             'prove': 490,\n",
       "             'television': 491,\n",
       "             'image': 492,\n",
       "             'clearly': 493,\n",
       "             'apparently': 494,\n",
       "             'wear': 495,\n",
       "             'charm': 496,\n",
       "             'air': 497,\n",
       "             'remain': 498,\n",
       "             'king': 499,\n",
       "             'discover': 500,\n",
       "             'space': 501,\n",
       "             'gun': 502,\n",
       "             'street': 503,\n",
       "             'avoid': 504,\n",
       "             'clear': 505,\n",
       "             'imagine': 506,\n",
       "             'escape': 507,\n",
       "             'member': 508,\n",
       "             'doubt': 509,\n",
       "             'stage': 510,\n",
       "             'villain': 511,\n",
       "             'basically': 512,\n",
       "             'jack': 513,\n",
       "             'capture': 514,\n",
       "             'date': 515,\n",
       "             'marry': 516,\n",
       "             'western': 517,\n",
       "             'earth': 518,\n",
       "             'remind': 519,\n",
       "             'mystery': 520,\n",
       "             'soldier': 521,\n",
       "             'weak': 522,\n",
       "             'fire': 523,\n",
       "             'fit': 524,\n",
       "             'plan': 525,\n",
       "             'straight': 526,\n",
       "             'crime': 527,\n",
       "             'entertainment': 528,\n",
       "             'romantic': 529,\n",
       "             'british': 530,\n",
       "             'aspect': 531,\n",
       "             'predictable': 532,\n",
       "             'soundtrack': 533,\n",
       "             'box': 534,\n",
       "             'future': 535,\n",
       "             'french': 536,\n",
       "             'easily': 537,\n",
       "             'dull': 538,\n",
       "             'send': 539,\n",
       "             'peter': 540,\n",
       "             'enjoyable': 541,\n",
       "             'copy': 542,\n",
       "             'thank': 543,\n",
       "             'george': 544,\n",
       "             'carry': 545,\n",
       "             'bunch': 546,\n",
       "             'battle': 547,\n",
       "             'certain': 548,\n",
       "             'chase': 549,\n",
       "             'similar': 550,\n",
       "             'agree': 551,\n",
       "             'doctor': 552,\n",
       "             'confuse': 553,\n",
       "             'suck': 554,\n",
       "             'adult': 555,\n",
       "             'choose': 556,\n",
       "             'attack': 557,\n",
       "             'mark': 558,\n",
       "             'student': 559,\n",
       "             'general': 560,\n",
       "             'suspense': 561,\n",
       "             'emotion': 562,\n",
       "             'lie': 563,\n",
       "             'mess': 564,\n",
       "             'storyline': 565,\n",
       "             'animation': 566,\n",
       "             'typical': 567,\n",
       "             'water': 568,\n",
       "             'standard': 569,\n",
       "             'period': 570,\n",
       "             'victim': 571,\n",
       "             'visual': 572,\n",
       "             'contain': 573,\n",
       "             'cry': 574,\n",
       "             'eat': 575,\n",
       "             'actual': 576,\n",
       "             'material': 577,\n",
       "             'reveal': 578,\n",
       "             'notice': 579,\n",
       "             'rend': 580,\n",
       "             'mix': 581,\n",
       "             'famous': 582,\n",
       "             'fly': 583,\n",
       "             'sorry': 584,\n",
       "             'bill': 585,\n",
       "             'issue': 586,\n",
       "             'hide': 587,\n",
       "             'fantastic': 588,\n",
       "             'match': 589,\n",
       "             'trouble': 590,\n",
       "             'romance': 591,\n",
       "             'spoiler': 592,\n",
       "             'large': 593,\n",
       "             'red': 594,\n",
       "             'excite': 595,\n",
       "             'premise': 596,\n",
       "             'suffer': 597,\n",
       "             'oscar': 598,\n",
       "             'ride': 599,\n",
       "             'finish': 600,\n",
       "             'continue': 601,\n",
       "             'nearly': 602,\n",
       "             'beat': 603,\n",
       "             'hot': 604,\n",
       "             'admit': 605,\n",
       "             'vampire': 606,\n",
       "             'blow': 607,\n",
       "             'realistic': 608,\n",
       "             'dr': 609,\n",
       "             'male': 610,\n",
       "             'dumb': 611,\n",
       "             'believable': 612,\n",
       "             'describe': 613,\n",
       "             'lame': 614,\n",
       "             'list': 615,\n",
       "             'paul': 616,\n",
       "             'alien': 617,\n",
       "             'free': 618,\n",
       "             'forward': 619,\n",
       "             'richard': 620,\n",
       "             '$': 621,\n",
       "             'atmosphere': 622,\n",
       "             'fi': 623,\n",
       "             'party': 624,\n",
       "             'average': 625,\n",
       "             'truth': 626,\n",
       "             'sci': 627,\n",
       "             'appreciate': 628,\n",
       "             'cartoon': 629,\n",
       "             'crow': 630,\n",
       "             'america': 631,\n",
       "             'bother': 632,\n",
       "             'particular': 633,\n",
       "             'odd': 634,\n",
       "             'treat': 635,\n",
       "             'studio': 636,\n",
       "             'spirit': 637,\n",
       "             'background': 638,\n",
       "             'baby': 639,\n",
       "             'appeal': 640,\n",
       "             'remake': 641,\n",
       "             'wood': 642,\n",
       "             'gay': 643,\n",
       "             'scare': 644,\n",
       "             'possibly': 645,\n",
       "             'shame': 646,\n",
       "             'secret': 647,\n",
       "             'difficult': 648,\n",
       "             'emotional': 649,\n",
       "             'society': 650,\n",
       "             'tom': 651,\n",
       "             'weird': 652,\n",
       "             'beauty': 653,\n",
       "             'girlfriend': 654,\n",
       "             'drink': 655,\n",
       "             'master': 656,\n",
       "             'masterpiece': 657,\n",
       "             'footage': 658,\n",
       "             's': 659,\n",
       "             'poorly': 660,\n",
       "             'sexual': 661,\n",
       "             'mistake': 662,\n",
       "             'rich': 663,\n",
       "             'eventually': 664,\n",
       "             'york': 665,\n",
       "             'lover': 666,\n",
       "             'control': 667,\n",
       "             'award': 668,\n",
       "             'adventure': 669,\n",
       "             'de': 670,\n",
       "             'screenplay': 671,\n",
       "             'week': 672,\n",
       "             'fear': 673,\n",
       "             'choice': 674,\n",
       "             'cliché': 675,\n",
       "             'japanese': 676,\n",
       "             'costume': 677,\n",
       "             'lee': 678,\n",
       "             'crazy': 679,\n",
       "             'accent': 680,\n",
       "             'plus': 681,\n",
       "             'suggest': 682,\n",
       "             'inside': 683,\n",
       "             'struggle': 684,\n",
       "             'incredibly': 685,\n",
       "             'memorable': 686,\n",
       "             'imdb': 687,\n",
       "             'cheesy': 688,\n",
       "             'brain': 689,\n",
       "             'tear': 690,\n",
       "             'superb': 691,\n",
       "             'flaw': 692,\n",
       "             'animal': 693,\n",
       "             'respect': 694,\n",
       "             'development': 695,\n",
       "             'badly': 696,\n",
       "             'scream': 697,\n",
       "             'previous': 698,\n",
       "             'total': 699,\n",
       "             'perfectly': 700,\n",
       "             'jump': 701,\n",
       "             'track': 702,\n",
       "             'project': 703,\n",
       "             'location': 704,\n",
       "             'fantasy': 705,\n",
       "             'teen': 706,\n",
       "             'personal': 707,\n",
       "             'disney': 708,\n",
       "             'dramatic': 709,\n",
       "             'rise': 710,\n",
       "             'nature': 711,\n",
       "             'quickly': 712,\n",
       "             'warn': 713,\n",
       "             'maker': 714,\n",
       "             'business': 715,\n",
       "             'company': 716,\n",
       "             'answer': 717,\n",
       "             'creepy': 718,\n",
       "             'color': 719,\n",
       "             'sell': 720,\n",
       "             'term': 721,\n",
       "             'dress': 722,\n",
       "             'island': 723,\n",
       "             'joe': 724,\n",
       "             'plenty': 725,\n",
       "             'land': 726,\n",
       "             'disturb': 727,\n",
       "             'store': 728,\n",
       "             'cute': 729,\n",
       "             'political': 730,\n",
       "             'fairly': 731,\n",
       "             'powerful': 732,\n",
       "             'serve': 733,\n",
       "             '`': 734,\n",
       "             'concern': 735,\n",
       "             'promise': 736,\n",
       "             'unique': 737,\n",
       "             'post': 738,\n",
       "             'plain': 739,\n",
       "             'rip': 740,\n",
       "             'outside': 741,\n",
       "             'amuse': 742,\n",
       "             'office': 743,\n",
       "             'law': 744,\n",
       "             'clever': 745,\n",
       "             'destroy': 746,\n",
       "             'portrayal': 747,\n",
       "             'design': 748,\n",
       "             'century': 749,\n",
       "             'appearance': 750,\n",
       "             'accept': 751,\n",
       "             'channel': 752,\n",
       "             'depth': 753,\n",
       "             'success': 754,\n",
       "             'blue': 755,\n",
       "             'william': 756,\n",
       "             'hole': 757,\n",
       "             'roll': 758,\n",
       "             'era': 759,\n",
       "             'inspire': 760,\n",
       "             'perform': 761,\n",
       "             'cat': 762,\n",
       "             'exist': 763,\n",
       "             'concept': 764,\n",
       "             'ability': 765,\n",
       "             'kick': 766,\n",
       "             'recently': 767,\n",
       "             'talented': 768,\n",
       "             'creature': 769,\n",
       "             'player': 770,\n",
       "             'band': 771,\n",
       "             'memory': 772,\n",
       "             'share': 773,\n",
       "             'ghost': 774,\n",
       "             'step': 775,\n",
       "             'sleep': 776,\n",
       "             'familiar': 777,\n",
       "             'cold': 778,\n",
       "             'pop': 779,\n",
       "             'spot': 780,\n",
       "             'soul': 781,\n",
       "             'filmmakers': 782,\n",
       "             'flat': 783,\n",
       "             'german': 784,\n",
       "             'culture': 785,\n",
       "             'door': 786,\n",
       "             'listen': 787,\n",
       "             'travel': 788,\n",
       "             'apart': 789,\n",
       "             'sing': 790,\n",
       "             'record': 791,\n",
       "             'reach': 792,\n",
       "             'camp': 793,\n",
       "             'hardly': 794,\n",
       "             'burn': 795,\n",
       "             'science': 796,\n",
       "             'jane': 797,\n",
       "             'tension': 798,\n",
       "             'pure': 799,\n",
       "             'van': 800,\n",
       "             'sweet': 801,\n",
       "             'incredible': 802,\n",
       "             'introduce': 803,\n",
       "             'claim': 804,\n",
       "             'public': 805,\n",
       "             'extra': 806,\n",
       "             'relate': 807,\n",
       "             'la': 808,\n",
       "             'nudity': 809,\n",
       "             'gang': 810,\n",
       "             'search': 811,\n",
       "             'potential': 812,\n",
       "             'italian': 813,\n",
       "             'receive': 814,\n",
       "             'language': 815,\n",
       "             'tone': 816,\n",
       "             'drag': 817,\n",
       "             'strike': 818,\n",
       "             'not': 819,\n",
       "             'rent': 820,\n",
       "             'slightly': 821,\n",
       "             'co': 822,\n",
       "             'intrigue': 823,\n",
       "             'park': 824,\n",
       "             'race': 825,\n",
       "             'approach': 826,\n",
       "             'suit': 827,\n",
       "             'unlike': 828,\n",
       "             'hang': 829,\n",
       "             'wind': 830,\n",
       "             'ruin': 831,\n",
       "             'count': 832,\n",
       "             'common': 833,\n",
       "             'ring': 834,\n",
       "             'edge': 835,\n",
       "             'drop': 836,\n",
       "             'college': 837,\n",
       "             'hair': 838,\n",
       "             'taste': 839,\n",
       "             'engage': 840,\n",
       "             'rape': 841,\n",
       "             'entirely': 842,\n",
       "             'mad': 843,\n",
       "             'basic': 844,\n",
       "             'popular': 845,\n",
       "             'intelligent': 846,\n",
       "             'smart': 847,\n",
       "             'sick': 848,\n",
       "             'fake': 849,\n",
       "             'bond': 850,\n",
       "             'social': 851,\n",
       "             'bizarre': 852,\n",
       "             'suddenly': 853,\n",
       "             'anti': 854,\n",
       "             'fashion': 855,\n",
       "             'clothe': 856,\n",
       "             'scott': 857,\n",
       "             'trip': 858,\n",
       "             'positive': 859,\n",
       "             'wild': 860,\n",
       "             'critic': 861,\n",
       "             'purpose': 862,\n",
       "             'computer': 863,\n",
       "             'handle': 864,\n",
       "             'ship': 865,\n",
       "             'successful': 866,\n",
       "             'alive': 867,\n",
       "             'adaptation': 868,\n",
       "             'ben': 869,\n",
       "             'survive': 870,\n",
       "             'road': 871,\n",
       "             'fiction': 872,\n",
       "             'judge': 873,\n",
       "             'super': 874,\n",
       "             'scientist': 875,\n",
       "             'fascinate': 876,\n",
       "             'visit': 877,\n",
       "             'torture': 878,\n",
       "             'teenager': 879,\n",
       "             'prison': 880,\n",
       "             'christmas': 881,\n",
       "             'develope': 882,\n",
       "             'violent': 883,\n",
       "             'tough': 884,\n",
       "             'impressive': 885,\n",
       "             'sadly': 886,\n",
       "             'genius': 887,\n",
       "             'hurt': 888,\n",
       "             'raise': 889,\n",
       "             'army': 890,\n",
       "             'barely': 891,\n",
       "             'wall': 892,\n",
       "             'awesome': 893,\n",
       "             'fair': 894,\n",
       "             'rule': 895,\n",
       "             'difference': 896,\n",
       "             'personality': 897,\n",
       "             'humour': 898,\n",
       "             'suspect': 899,\n",
       "             'reference': 900,\n",
       "             'pointless': 901,\n",
       "             'cross': 902,\n",
       "             'reviewer': 903,\n",
       "             'planet': 904,\n",
       "             'seek': 905,\n",
       "             'giant': 906,\n",
       "             'club': 907,\n",
       "             'artist': 908,\n",
       "             'animate': 909,\n",
       "             'slasher': 910,\n",
       "             'honest': 911,\n",
       "             'conclusion': 912,\n",
       "             'recent': 913,\n",
       "             'sign': 914,\n",
       "             'solid': 915,\n",
       "             'impress': 916,\n",
       "             'intend': 917,\n",
       "             'folk': 918,\n",
       "             'bar': 919,\n",
       "             'trash': 920,\n",
       "             'government': 921,\n",
       "             'aside': 922,\n",
       "             'heavy': 923,\n",
       "             'mood': 924,\n",
       "             'normal': 925,\n",
       "             'compel': 926,\n",
       "             'ultimately': 927,\n",
       "             'revenge': 928,\n",
       "             'cult': 929,\n",
       "             'singe': 930,\n",
       "             'charles': 931,\n",
       "             'effective': 932,\n",
       "             'study': 933,\n",
       "             'detective': 934,\n",
       "             'motion': 935,\n",
       "             'haunt': 936,\n",
       "             'journey': 937,\n",
       "             'pathetic': 938,\n",
       "             'excuse': 939,\n",
       "             'arrive': 940,\n",
       "             'trailer': 941,\n",
       "             'frank': 942,\n",
       "             'foot': 943,\n",
       "             'tire': 944,\n",
       "             'cost': 945,\n",
       "             'stun': 946,\n",
       "             'chemistry': 947,\n",
       "             'sexy': 948,\n",
       "             'impossible': 949,\n",
       "             'surprisingly': 950,\n",
       "             'machine': 951,\n",
       "             'jim': 952,\n",
       "             'south': 953,\n",
       "             'enter': 954,\n",
       "             'bed': 955,\n",
       "             'limit': 956,\n",
       "             'horse': 957,\n",
       "             'literally': 958,\n",
       "             'interview': 959,\n",
       "             'agent': 960,\n",
       "             'dad': 961,\n",
       "             'opportunity': 962,\n",
       "             'steve': 963,\n",
       "             'immediately': 964,\n",
       "             'ray': 965,\n",
       "             'affair': 966,\n",
       "             'garbage': 967,\n",
       "             'pain': 968,\n",
       "             'arm': 969,\n",
       "             'grade': 970,\n",
       "             'glad': 971,\n",
       "             'plane': 972,\n",
       "             'opus': 973,\n",
       "             'ex': 974,\n",
       "             'honestly': 975,\n",
       "             'mouth': 976,\n",
       "             'repeat': 977,\n",
       "             'key': 978,\n",
       "             'military': 979,\n",
       "             'naked': 980,\n",
       "             'display': 981,\n",
       "             'generally': 982,\n",
       "             'sam': 983,\n",
       "             'jones': 984,\n",
       "             'festival': 985,\n",
       "             'innocent': 986,\n",
       "             'commit': 987,\n",
       "             'smile': 988,\n",
       "             'mary': 989,\n",
       "             'silent': 990,\n",
       "             'paint': 991,\n",
       "             'moral': 992,\n",
       "             'criminal': 993,\n",
       "             'stereotype': 994,\n",
       "             'boyfriend': 995,\n",
       "             'subtle': 996,\n",
       "             'complex': 997,\n",
       "             'impression': 998,\n",
       "             'london': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display word2index dictionary\n",
    "val_vocab.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 387,  458,   38,   11,    5, 1011,   64, 1949,    5, 1447, 1641,\n",
       "          4,    3, 2101, 2861,   23,  585,  794,    5,   26,  292, 2768,\n",
       "         49,   62,  165,  663,   44,   31,   36,  226,   26, 1279,  809,\n",
       "          5, 3140,   62,  165,  119,   74,  132,   19, 2768, 4237, 1272,\n",
       "         50,  730,  473,    6,    5,  795, 1641,   33, 1554,   12,  685,\n",
       "        423,  222,   57,   28,  151,   23,  333,   47,    5,   77,   22,\n",
       "        809,  237, 1391,  208,  680,    7, 1094,   22,    5,   23,  605,\n",
       "         36,  423,    2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depict the first dataset sequence\n",
    "val_vocab.dataset[10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task to do is to create the BatchIterator class that will enable to sort dataset examples, generate batches of input and output variables, apply padding if required and be capable of iterating through all created batches. To warrant that the padding operation within one batch is limited, we have to sort examples within entire dataset according to sequences lengths, so that each batch will contain sequences with the most similar lengths and the number of padding tokens will be reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchIterator:\n",
    "    \n",
    "    \"\"\"The BatchIterator class is responsible for:\n",
    "    Sorting dataset examples.\n",
    "    Generating batches.\n",
    "    Sequence padding.\n",
    "    Enabling BatchIterator instance to iterate through all batches.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : pandas.DataFrame or numpy.ndarray\n",
    "        If vocab_created is False, pass Pandas or numpy dataset containing in the first column input strings\n",
    "        to process and target non-string variable as last column. Otherwise pass vocab.dataset object.\n",
    "    batch_size: int, optional (default=None)\n",
    "        The size of the batch. By default use batch_size equal to the dataset length.\n",
    "    vocab_created: boolean, optional (default=True)\n",
    "        Whether the vocab object is already created.\n",
    "    vocab: Vocab object, optional (default=None)\n",
    "        Use if vocab_created = True, pass the vocab object.\n",
    "    target_col: int, optional (default=None)\n",
    "        Column index refering to targets strings to process.\n",
    "    word2index: dict, optional (default=None)\n",
    "        Specify the word2index mapping.\n",
    "    sos_token: str, optional (default='<SOS>')\n",
    "        Use if vocab_created = False. Start of sentence token.\n",
    "    eos_token: str, optional (default='<EOS>')\n",
    "        Use if vocab_created = False. End of sentence token.\n",
    "    unk_token: str, optional (default='<UNK>')\n",
    "        Use if vocab_created = False. Token that represents unknown words.\n",
    "    pad_token: str, optional (default='<PAD>')\n",
    "        Use if vocab_created = False. Token that represents padding.\n",
    "    min_word_count: float, optional (default=5)\n",
    "        Use if vocab_created = False. Specify the minimum word count threshold to include a word in vocabulary\n",
    "        if value > 1 was passed. If min_word_count <= 1 then keep all words whose count is greater than the\n",
    "        quantile=min_word_count of the count distribution.\n",
    "    max_vocab_size: int, optional (default=None)\n",
    "        Use if vocab_created = False. Maximum size of the vocabulary.\n",
    "    max_seq_len: float, optional (default=0.8)\n",
    "        Use if vocab_created = False. Specify the maximum length of the sequence in the dataset, if \n",
    "        max_seq_len > 1. If max_seq_len <= 1 then set the maximum length to value corresponding to\n",
    "        quantile=max_seq_len of lengths distribution. Trimm all sequences whose lengths are greater\n",
    "        than max_seq_len.\n",
    "    use_pretrained_vectors: boolean, optional (default=False)\n",
    "        Use if vocab_created = False. Whether to use pre-trained Glove vectors.\n",
    "    glove_path: str, optional (default='Glove/')\n",
    "        Use if vocab_created = False. Path to the directory that contains files with the Glove word vectors.\n",
    "    glove_name: str, optional (default='glove.6B.100d.txt')\n",
    "        Use if vocab_created = False. Name of the Glove word vectors file. Available pretrained vectors:\n",
    "        glove.6B.50d.txt\n",
    "        glove.6B.100d.txt\n",
    "        glove.6B.200d.txt\n",
    "        glove.6B.300d.txt\n",
    "        glove.twitter.27B.50d.txt\n",
    "        To use different word vectors, load their file to the vectors directory (Glove/).\n",
    "    weights_file_name: str, optional (default='Glove/weights.npy')\n",
    "        Use if vocab_created = False. The path and the name of the numpy file to which save weights vectors.\n",
    "\n",
    "    Raises\n",
    "    -------\n",
    "    ValueError('Use min_word_count or max_vocab_size, not both!')\n",
    "        If both: min_word_count and max_vocab_size are provided.\n",
    "    FileNotFoundError\n",
    "        If the glove file doesn't exist in the given directory.\n",
    "    TypeError('Cannot convert to Tensor. Data type not recognized')\n",
    "        If the data type of the sequence cannot be converted to the Tensor.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    dict\n",
    "        Dictionary that contains variables batches.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "    def __init__(self, dataset, batch_size=None, vocab_created=False, vocab=None, target_col=None, word2index=None,\n",
    "             sos_token='<SOS>', eos_token='<EOS>', unk_token='<UNK>', pad_token='<PAD>', min_word_count=5,\n",
    "             max_vocab_size=None, max_seq_len=0.8, use_pretrained_vectors=False, glove_path='Glove/',\n",
    "             glove_name='glove.6B.100d.txt', weights_file_name='Glove/weights.npy'):    \n",
    "    \n",
    "        # Create vocabulary object\n",
    "        if not vocab_created:\n",
    "            self.vocab = Vocab(dataset, target_col=target_col, word2index=word2index, sos_token=sos_token, eos_token=eos_token,\n",
    "                               unk_token=unk_token, pad_token=pad_token, min_word_count=min_word_count,\n",
    "                               max_vocab_size=max_vocab_size, max_seq_len=max_seq_len,\n",
    "                               use_pretrained_vectors=use_pretrained_vectors, glove_path=glove_path,\n",
    "                               glove_name=glove_name, weights_file_name=weights_file_name)\n",
    "            \n",
    "            # Use created vocab.dataset object\n",
    "            self.dataset = self.vocab.dataset      \n",
    "        \n",
    "        else:\n",
    "            # If vocab was created then dataset should be the vocab.dataset object\n",
    "            self.dataset = dataset\n",
    "            self.vocab = vocab\n",
    "            \n",
    "        self.target_col = target_col \n",
    "        \n",
    "        self.word2index = self.vocab.word2index\n",
    "            \n",
    "        # Define the batch_size\n",
    "        if batch_size:\n",
    "            self.batch_size = batch_size\n",
    "        else:\n",
    "            # Use the length of dataset as batch_size\n",
    "            self.batch_size = len(self.dataset)\n",
    "                \n",
    "        self.x_lengths = np.array(self.vocab.x_lengths)\n",
    "        \n",
    "        if self.target_col:\n",
    "            self.y_lengths = np.array(self.vocab.y_lengths)\n",
    "            \n",
    "        self.pad_token = self.vocab.word2index[pad_token]\n",
    "            \n",
    "        self.sort_and_batch()\n",
    "\n",
    "        \n",
    "    def sort_and_batch(self):\n",
    "        \"\"\" Sort examples within entire dataset, then perform batching and shuffle all batches.\n",
    "\n",
    "        \"\"\"\n",
    "        # Extract row indices sorted according to lengths\n",
    "        if not self.target_col:\n",
    "            sorted_indices = np.argsort(self.x_lengths)\n",
    "        else:\n",
    "            sorted_indices = np.lexsort((self.y_lengths, self.x_lengths))\n",
    "        \n",
    "        # Sort all sets\n",
    "        self.sorted_dataset = self.dataset[sorted_indices[::-1]]\n",
    "        self.sorted_x_lengths = np.flip(self.x_lengths[sorted_indices])\n",
    "        \n",
    "        if self.target_col:\n",
    "            self.sorted_target = self.sorted_dataset[:, self.target_col]\n",
    "            self.sorted_y_lengths = np.flip(self.x_lengths[sorted_indices])\n",
    "        else:\n",
    "            self.sorted_target = self.sorted_dataset[:, -1]\n",
    "        \n",
    "        # Initialize input, target and lengths batches\n",
    "        self.input_batches = [[] for _ in range(self.sorted_dataset.shape[1]-1)]\n",
    "        \n",
    "        self.target_batches, self.x_len_batches = [], []\n",
    "\n",
    "        self.y_len_batches = [] if self.target_col else None\n",
    "        \n",
    "        # Create batches\n",
    "        for i in range(self.sorted_dataset.shape[1]-1):\n",
    "            # The first column contains always sequences that should be padded.\n",
    "            if i == 0:\n",
    "                self.create_batches(self.sorted_dataset[:, i], self.input_batches[i], pad_token=self.pad_token)\n",
    "            else:\n",
    "                self.create_batches(self.sorted_dataset[:, i], self.input_batches[i])\n",
    "                \n",
    "        if self.target_col:\n",
    "            self.create_batches(self.sorted_target, self.target_batches, pad_token=self.pad_token)\n",
    "            self.create_batches(self.sorted_y_lengths, self.y_len_batches)\n",
    "        else:\n",
    "            self.create_batches(self.sorted_target, self.target_batches)\n",
    "        \n",
    "        self.create_batches(self.sorted_x_lengths, self.x_len_batches)\n",
    "        \n",
    "        # Shuffle batches\n",
    "        self.indices = np.arange(len(self.input_batches[0]))\n",
    "        np.random.shuffle(self.indices)\n",
    "        \n",
    "        for j in range(self.sorted_dataset.shape[1]-1):\n",
    "            self.input_batches[j] = [self.input_batches[j][i] for i in self.indices]\n",
    "        \n",
    "        self.target_batches = [self.target_batches[i] for i in self.indices]\n",
    "        self.x_len_batches = [self.x_len_batches[i] for i in self.indices]\n",
    "        \n",
    "        if self.target_col:\n",
    "            self.y_len_batches = [self.y_len_batches[i] for i in self.indices]\n",
    "        \n",
    "        print('Batches created')\n",
    "        \n",
    "        \n",
    "    def create_batches(self, sorted_dataset, batches, pad_token=-1):\n",
    "        \"\"\" Convert each sequence to pytorch Tensor, create batches and pad them if required.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Calculate the number of batches\n",
    "        n_batches = int(len(sorted_dataset)/self.batch_size)\n",
    "\n",
    "        # Create list of batches\n",
    "        list_of_batches = np.array([sorted_dataset[i*self.batch_size:(i+1)*self.batch_size].copy()\\\n",
    "                                    for i in range(n_batches+1)])\n",
    "\n",
    "        # Convert each sequence to pytorch Tensor\n",
    "        for batch in list_of_batches:\n",
    "            tensor_batch = []\n",
    "            tensor_type = None\n",
    "            for seq in batch:\n",
    "                # Check seq data type and convert to Tensor\n",
    "                if isinstance(seq, np.ndarray):\n",
    "                    tensor = torch.LongTensor(seq)\n",
    "                    tensor_type = 'int'\n",
    "                elif isinstance(seq, np.integer):\n",
    "                    tensor = torch.LongTensor([seq])\n",
    "                    tensor_type = 'int'\n",
    "                elif isinstance(seq, np.float):\n",
    "                    tensor = torch.FloatTensor([seq])\n",
    "                    tensor_type = 'float'\n",
    "                elif isinstance(seq, int):\n",
    "                    tensor = torch.LongTensor([seq])\n",
    "                    tensor_type = 'int'\n",
    "                elif isinstance(seq, float):\n",
    "                    tensor = torch.FloatTensor([seq])\n",
    "                    tensor_type = 'float'\n",
    "                else:\n",
    "                    raise TypeError('Cannot convert to Tensor. Data type not recognized')\n",
    "\n",
    "                tensor_batch.append(tensor)\n",
    "            if pad_token != -1:\n",
    "                # Pad required sequences\n",
    "                pad_batch = torch.nn.utils.rnn.pad_sequence(tensor_batch, batch_first=True)\n",
    "                batches.append(pad_batch)\n",
    "            else:\n",
    "                if tensor_type == 'int':\n",
    "                    batches.append(torch.LongTensor(tensor_batch))\n",
    "                else:\n",
    "                    batches.append(torch.FloatTensor(tensor_batch))\n",
    "\n",
    "                \n",
    "    def __iter__(self):\n",
    "        \"\"\" Iterate through batches.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Create a dictionary that holds variables batches to yield\n",
    "        to_yield = {}\n",
    "        \n",
    "        # Iterate through batches\n",
    "        for i in range(len(self.input_batches[0])):\n",
    "\n",
    "            for j in range(len(self.input_batches)):\n",
    "                to_yield['input_{}'.format(j)] = self.input_batches[j][i]\n",
    "                \n",
    "            to_yield['target'] = self.target_batches[i]\n",
    "            to_yield['x_lengths'] = self.x_len_batches[i]\n",
    "            \n",
    "            if self.target_col:\n",
    "                to_yield['y_length'] = self.y_len_batches[i]\n",
    "\n",
    "\n",
    "            yield to_yield\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\" Return iterator length.\n",
    "        \n",
    "        \"\"\"\n",
    "        return len(self.input_batches[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to instantiate the BatchIterator class and check out whether all tasks were conducted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed vocabulary using as minimum count threashold: count = 5.00\n",
      "26346/130416 tokens has been retained\n",
      "Trimmed input strings vocabulary\n",
      "Trimmed input sequences lengths to the length of: 138\n",
      "Mapped words to indices\n",
      "Batches created\n"
     ]
    }
   ],
   "source": [
    "train_iterator = BatchIterator(train_dataset, batch_size=32, vocab_created=False, vocab=None, target_col=None,\n",
    "                               word2index=None, sos_token='<SOS>', eos_token='<EOS>', unk_token='<UNK>',\n",
    "                               pad_token='<PAD>', min_word_count=5, max_vocab_size=None, max_seq_len=0.8,\n",
    "                               use_pretrained_vectors=False, glove_path='glove/', glove_name='glove.6B.100d.txt',\n",
    "                               weights_file_name='glove/weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the size of first input batch\n",
    "len(train_iterator.input_batches[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_0': tensor([[  173,   692,  2273,  ...,  5350,   135,     2],\n",
      "        [ 4692,   165,  2234,  ...,  2234,  1449,     2],\n",
      "        [ 1051,   173,    28,  ...,  3564,   485,     2],\n",
      "        ...,\n",
      "        [   74,    28,     7,  ...,  1276,  1524,     2],\n",
      "        [  463, 14307,     5,  ...,   565,   416,     2],\n",
      "        [ 4889, 14402,   968,  ...,   633,  2163,     2]]),\n",
      " 'input_1': tensor([-0.1105, -0.0653, -0.0124, -0.0297,  0.0717,  0.0883, -0.0433,  0.2168,\n",
      "         0.1687,  0.1799,  0.0545, -0.1493,  0.4133,  0.0135,  0.0040,  0.2640,\n",
      "         0.0687, -0.0337,  0.0461, -0.1031,  0.0701,  0.2874,  0.1074, -0.0500,\n",
      "         0.2964,  0.1423,  0.0289,  0.2441,  0.2040,  0.0717,  0.1062,  0.1110]),\n",
      " 'input_2': tensor([243, 201, 276, 243, 247, 236, 278, 196, 211, 223, 242, 234, 245, 259,\n",
      "        271, 222, 227, 235, 287, 214, 249, 237, 234, 209, 237, 249, 317, 221,\n",
      "        287, 262, 273, 215]),\n",
      " 'target': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1]),\n",
      " 'x_lengths': tensor([107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
      "        107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107,\n",
      "        107, 107, 107, 107])}\n"
     ]
    }
   ],
   "source": [
    "# Run the BatchIterator and print the first set of batches\n",
    "for batches in train_iterator:\n",
    "    pprint(batches)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed vocabulary using as minimum count threashold: count = 5.00\n",
      "14097/59089 tokens has been retained\n",
      "Trimmed input strings vocabulary\n",
      "Trimmed input sequences lengths to the length of: 132\n",
      "Mapped words to indices\n",
      "Batches created\n"
     ]
    }
   ],
   "source": [
    "val_iterator = BatchIterator(val_dataset, batch_size=32, vocab_created=False, vocab=None, target_col=None,\n",
    "                             word2index=train_iterator.word2index, sos_token='<SOS>', eos_token='<EOS>',\n",
    "                             unk_token='<UNK>', pad_token='<PAD>', min_word_count=5, max_vocab_size=None,\n",
    "                             max_seq_len=0.8, use_pretrained_vectors=False, glove_path='glove/',\n",
    "                             glove_name='glove.6B.100d.txt', weights_file_name='glove/weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.Vocab.mapWord2index.<locals>.<lambda>()>,\n",
       "            {'<PAD>': 0,\n",
       "             '<SOS>': 1,\n",
       "             '<EOS>': 2,\n",
       "             '<UNK>': 3,\n",
       "             'amaze': 4,\n",
       "             'good': 5,\n",
       "             'wonderful': 6,\n",
       "             'film': 7,\n",
       "             'early': 8,\n",
       "             'ninety': 9,\n",
       "             'franchise': 10,\n",
       "             'grow': 11,\n",
       "             'stargate': 12,\n",
       "             'sg1': 13,\n",
       "             'doubt': 14,\n",
       "             'worthy': 15,\n",
       "             'addition': 16,\n",
       "             'science': 17,\n",
       "             'fiction': 18,\n",
       "             'genre': 19,\n",
       "             'right': 20,\n",
       "             'stand': 21,\n",
       "             'shoulder': 22,\n",
       "             'star': 23,\n",
       "             'trek': 24,\n",
       "             'king': 25,\n",
       "             'feature': 26,\n",
       "             'series': 27,\n",
       "             'see': 28,\n",
       "             'command': 29,\n",
       "             'military': 30,\n",
       "             'organisation': 31,\n",
       "             'figure': 32,\n",
       "             'system': 33,\n",
       "             'travel': 34,\n",
       "             'planet': 35,\n",
       "             'galaxy': 36,\n",
       "             'set': 37,\n",
       "             'numb': 38,\n",
       "             'team': 39,\n",
       "             'explore': 40,\n",
       "             'head': 41,\n",
       "             'veteran': 42,\n",
       "             'colonel': 43,\n",
       "             'jack': 44,\n",
       "             \"o'neill\": 45,\n",
       "             'include': 46,\n",
       "             'archaeologist': 47,\n",
       "             'doctor': 48,\n",
       "             'daniel': 49,\n",
       "             'jackson': 50,\n",
       "             'scientist': 51,\n",
       "             'captain': 52,\n",
       "             'samantha': 53,\n",
       "             'carter': 54,\n",
       "             'alien': 55,\n",
       "             \"teal'c\": 56,\n",
       "             'betray': 57,\n",
       "             'overlord': 58,\n",
       "             'leader': 59,\n",
       "             'hope': 60,\n",
       "             'day': 61,\n",
       "             'free': 62,\n",
       "             'people': 63,\n",
       "             'earth': 64,\n",
       "             'quickly': 65,\n",
       "             'make': 66,\n",
       "             'enemy': 67,\n",
       "             \"goa'uld\": 68,\n",
       "             'parasitic': 69,\n",
       "             'race': 70,\n",
       "             'use': 71,\n",
       "             'human': 72,\n",
       "             'host': 73,\n",
       "             'think': 74,\n",
       "             'equal': 75,\n",
       "             'notch': 76,\n",
       "             'cast': 77,\n",
       "             'congratulate': 78,\n",
       "             'bring': 79,\n",
       "             'life': 80,\n",
       "             'richard': 81,\n",
       "             'dean': 82,\n",
       "             'anderson': 83,\n",
       "             'perfect': 84,\n",
       "             'cynical': 85,\n",
       "             'sarcastic': 86,\n",
       "             'shift': 87,\n",
       "             'boyish': 88,\n",
       "             'deadly': 89,\n",
       "             'blink': 90,\n",
       "             'eye': 91,\n",
       "             'michael': 92,\n",
       "             'shank': 93,\n",
       "             'heart': 94,\n",
       "             'steel': 95,\n",
       "             'character': 96,\n",
       "             'wide': 97,\n",
       "             'innocence': 98,\n",
       "             'dark': 99,\n",
       "             'hard': 100,\n",
       "             'bite': 101,\n",
       "             'progress': 102,\n",
       "             'amanda': 103,\n",
       "             'tap': 104,\n",
       "             'balance': 105,\n",
       "             'depict': 106,\n",
       "             'femininity': 107,\n",
       "             'comprise': 108,\n",
       "             'fact': 109,\n",
       "             'strong': 110,\n",
       "             'intelligent': 111,\n",
       "             'christopher': 112,\n",
       "             'judge': 113,\n",
       "             'excellent': 114,\n",
       "             'aloof': 115,\n",
       "             'able': 116,\n",
       "             'emotion': 117,\n",
       "             'subtlety': 118,\n",
       "             'don': 119,\n",
       "             's': 120,\n",
       "             'davis': 121,\n",
       "             'esteem': 122,\n",
       "             'general': 123,\n",
       "             'hammond': 124,\n",
       "             'lead': 125,\n",
       "             'fairness': 126,\n",
       "             'episode': 127,\n",
       "             'involve': 128,\n",
       "             'portray': 129,\n",
       "             'intelligence': 130,\n",
       "             'reflect': 131,\n",
       "             'moral': 132,\n",
       "             'dilemma': 133,\n",
       "             'friction': 134,\n",
       "             'interest': 135,\n",
       "             'civilian': 136,\n",
       "             'belief': 137,\n",
       "             'show': 138,\n",
       "             'argument': 139,\n",
       "             'guest': 140,\n",
       "             'solidly': 141,\n",
       "             'story': 142,\n",
       "             'arc': 143,\n",
       "             'handle': 144,\n",
       "             'manner': 145,\n",
       "             'bear': 146,\n",
       "             'viewer': 147,\n",
       "             'excel': 148,\n",
       "             'humour': 149,\n",
       "             'wisecrack': 150,\n",
       "             'wacky': 151,\n",
       "             'odd': 152,\n",
       "             'action': 153,\n",
       "             'drama': 154,\n",
       "             'romance': 155,\n",
       "             'suspense': 156,\n",
       "             'heartbreaking': 157,\n",
       "             'scene': 158,\n",
       "             'death': 159,\n",
       "             'sci': 160,\n",
       "             'fi': 161,\n",
       "             'overall': 162,\n",
       "             'wrong': 163,\n",
       "             'end': 164,\n",
       "             'tell': 165,\n",
       "             'chick': 166,\n",
       "             'go': 167,\n",
       "             'crazy': 168,\n",
       "             'eat': 169,\n",
       "             'old': 170,\n",
       "             'woman': 171,\n",
       "             'dose': 172,\n",
       "             'movie': 173,\n",
       "             'cheap': 174,\n",
       "             'crappy': 175,\n",
       "             'scare': 176,\n",
       "             'begin': 177,\n",
       "             'person': 178,\n",
       "             'die': 179,\n",
       "             'kill': 180,\n",
       "             'minute': 181,\n",
       "             'act': 182,\n",
       "             'credit': 183,\n",
       "             'porn': 184,\n",
       "             'well': 185,\n",
       "             'couple': 186,\n",
       "             'funny': 187,\n",
       "             'part': 188,\n",
       "             'like': 189,\n",
       "             'care': 190,\n",
       "             'taker': 191,\n",
       "             'get': 192,\n",
       "             'organ': 193,\n",
       "             'ass': 194,\n",
       "             'choke': 195,\n",
       "             'give': 196,\n",
       "             'suck': 197,\n",
       "             'rest': 198,\n",
       "             'great': 199,\n",
       "             'guess': 200,\n",
       "             'emperor': 201,\n",
       "             'clothe': 202,\n",
       "             'list': 203,\n",
       "             'pbs': 204,\n",
       "             'night': 205,\n",
       "             'hopeful': 206,\n",
       "             'apprehensive': 207,\n",
       "             'love': 208,\n",
       "             'morse': 209,\n",
       "             'far': 210,\n",
       "             'buy': 211,\n",
       "             'complete': 212,\n",
       "             'dvd': 213,\n",
       "             'feel': 214,\n",
       "             'kevin': 215,\n",
       "             'sgt': 216,\n",
       "             'lewis': 217,\n",
       "             'john': 218,\n",
       "             'thaw': 219,\n",
       "             'period': 220,\n",
       "             'watch': 221,\n",
       "             'new': 222,\n",
       "             'inspector': 223,\n",
       "             'bill': 224,\n",
       "             'convince': 225,\n",
       "             'fine': 226,\n",
       "             'look': 227,\n",
       "             'awful': 228,\n",
       "             'badly': 229,\n",
       "             'age': 230,\n",
       "             'fat': 231,\n",
       "             'simply': 232,\n",
       "             'charisma': 233,\n",
       "             'carry': 234,\n",
       "             'sidekick': 235,\n",
       "             'fox': 236,\n",
       "             'reviewer': 237,\n",
       "             'england': 238,\n",
       "             'understand': 239,\n",
       "             'say': 240,\n",
       "             'ms': 241,\n",
       "             'innocent': 242,\n",
       "             'miss': 243,\n",
       "             'james': 244,\n",
       "             'sorry': 245,\n",
       "             'leave': 246,\n",
       "             'peace': 247,\n",
       "             'sweet': 248,\n",
       "             'plot': 249,\n",
       "             'unique': 250,\n",
       "             'similar': 251,\n",
       "             'line': 252,\n",
       "             'comedy': 253,\n",
       "             'doe': 254,\n",
       "             'high': 255,\n",
       "             'school': 256,\n",
       "             'student': 257,\n",
       "             'kathleen': 258,\n",
       "             'beller': 259,\n",
       "             'find': 260,\n",
       "             'beat': 261,\n",
       "             'open': 262,\n",
       "             'tv': 263,\n",
       "             'flashback': 264,\n",
       "             'rape': 265,\n",
       "             'scott': 266,\n",
       "             'friend': 267,\n",
       "             'robin': 268,\n",
       "             'quaid': 269,\n",
       "             'double': 270,\n",
       "             'date': 271,\n",
       "             'anxious': 272,\n",
       "             'parent': 273,\n",
       "             'lay': 274,\n",
       "             'tony': 275,\n",
       "             'shrill': 276,\n",
       "             'blythe': 277,\n",
       "             'danner': 278,\n",
       "             'wait': 279,\n",
       "             'home': 280,\n",
       "             'away': 281,\n",
       "             'young': 282,\n",
       "             'discuss': 283,\n",
       "             'amateur': 284,\n",
       "             'photographer': 285,\n",
       "             'threaten': 286,\n",
       "             'locker': 287,\n",
       "             'maker': 288,\n",
       "             'wisely': 289,\n",
       "             'slay': 290,\n",
       "             'suspect': 291,\n",
       "             'boyfriend': 292,\n",
       "             'dad': 293,\n",
       "             'ex': 294,\n",
       "             'friendly': 295,\n",
       "             'photography': 296,\n",
       "             'class': 297,\n",
       "             'teacher': 298,\n",
       "             'want': 299,\n",
       "             'alittle': 300,\n",
       "             'sexy': 301,\n",
       "             'self': 302,\n",
       "             'portrait': 303,\n",
       "             'know': 304,\n",
       "             'rapist': 305,\n",
       "             'video': 306,\n",
       "             'company': 307,\n",
       "             'box': 308,\n",
       "             'picture': 309,\n",
       "             'ofthe': 310,\n",
       "             'attack': 311,\n",
       "             'cover': 312,\n",
       "             'destroy': 313,\n",
       "             'attacker': 314,\n",
       "             'phone': 315,\n",
       "             'call': 316,\n",
       "             'eventually': 317,\n",
       "             'south': 318,\n",
       "             'nancy': 319,\n",
       "             'draw': 320,\n",
       "             'secretly': 321,\n",
       "             'upa': 322,\n",
       "             'time': 323,\n",
       "             'lapse': 324,\n",
       "             'camera': 325,\n",
       "             'catch': 326,\n",
       "             'guy': 327,\n",
       "             'stalk': 328,\n",
       "             'tack': 329,\n",
       "             'hokey': 330,\n",
       "             'narration': 331,\n",
       "             'lack': 332,\n",
       "             'victim': 333,\n",
       "             'real': 334,\n",
       "             'stuff': 335,\n",
       "             'abandon': 336,\n",
       "             'job': 337,\n",
       "             'familiar': 338,\n",
       "             'face': 339,\n",
       "             'ellen': 340,\n",
       "             'travolta': 341,\n",
       "             'small': 342,\n",
       "             'role': 343,\n",
       "             'sure': 344,\n",
       "             'review': 345,\n",
       "             'lover': 346,\n",
       "             'need': 347,\n",
       "             'bed': 348,\n",
       "             'attitude': 349,\n",
       "             'embarassing': 350,\n",
       "             'explain': 351,\n",
       "             'mind': 352,\n",
       "             'nowadays': 353,\n",
       "             'issue': 354,\n",
       "             'blah': 355,\n",
       "             'case': 356,\n",
       "             'virgin': 357,\n",
       "             'prove': 358,\n",
       "             'problem': 359,\n",
       "             'address': 360,\n",
       "             'technology': 361,\n",
       "             'police': 362,\n",
       "             'effort': 363,\n",
       "             'chance': 364,\n",
       "             'add': 365,\n",
       "             'reform': 366,\n",
       "             'debate': 367,\n",
       "             'violence': 368,\n",
       "             'today': 369,\n",
       "             'mile': 370,\n",
       "             'ahead': 371,\n",
       "             'year': 372,\n",
       "             'ago': 373,\n",
       "             'anti': 374,\n",
       "             'angle': 375,\n",
       "             'tight': 376,\n",
       "             'little': 377,\n",
       "             'honest': 378,\n",
       "             'god': 379,\n",
       "             'characterization': 380,\n",
       "             'better.i': 381,\n",
       "             'remember': 382,\n",
       "             'reveal': 383,\n",
       "             'betsy': 384,\n",
       "             'shame': 385,\n",
       "             'then.i': 386,\n",
       "             'recommend': 387,\n",
       "             'house': 388,\n",
       "             'base': 389,\n",
       "             'reluctant': 390,\n",
       "             'nod': 391,\n",
       "             'third': 392,\n",
       "             'relive': 393,\n",
       "             'cup': 394,\n",
       "             'unrated': 395,\n",
       "             'contain': 396,\n",
       "             'physical': 397,\n",
       "             'adult': 398,\n",
       "             'situation': 399,\n",
       "             'geena': 400,\n",
       "             'fan': 401,\n",
       "             'samuel': 402,\n",
       "             'l': 403,\n",
       "             'pair': 404,\n",
       "             'screen': 405,\n",
       "             'forget': 406,\n",
       "             'twist': 407,\n",
       "             'ending': 408,\n",
       "             'audience': 409,\n",
       "             'come': 410,\n",
       "             'expect': 411,\n",
       "             'filmmakers': 412,\n",
       "             'try': 413,\n",
       "             'fail': 414,\n",
       "             'incorporate': 415,\n",
       "             'okay': 416,\n",
       "             'lady': 417,\n",
       "             'terrible': 418,\n",
       "             'man': 419,\n",
       "             'stephan': 420,\n",
       "             'jenkins': 421,\n",
       "             'play': 422,\n",
       "             'husband': 423,\n",
       "             'truly': 424,\n",
       "             'bad': 425,\n",
       "             'actor': 426,\n",
       "             'joyce': 427,\n",
       "             'hand': 428,\n",
       "             'save': 429,\n",
       "             'grace': 430,\n",
       "             'comment': 431,\n",
       "             'fellow': 432,\n",
       "             'heap': 433,\n",
       "             'praise': 434,\n",
       "             'accord': 435,\n",
       "             'imdb.com': 436,\n",
       "             'account': 437,\n",
       "             'write': 438,\n",
       "             'obviously': 439,\n",
       "             'plant': 440,\n",
       "             'nicely': 441,\n",
       "             'shoot': 442,\n",
       "             'mean': 443,\n",
       "             'subtle': 444,\n",
       "             'description': 445,\n",
       "             'revenge': 446,\n",
       "             'fair': 447,\n",
       "             'big': 448,\n",
       "             'tease': 449,\n",
       "             'offer': 450,\n",
       "             'sexual': 451,\n",
       "             'skin': 452,\n",
       "             'flick': 453,\n",
       "             'cinemax': 454,\n",
       "             'naughty': 455,\n",
       "             'bit': 456,\n",
       "             'edit': 457,\n",
       "             'out.the': 458,\n",
       "             'unfocused': 459,\n",
       "             'mess': 460,\n",
       "             'course': 461,\n",
       "             'necessary': 462,\n",
       "             'spoiler': 463,\n",
       "             'summary': 464,\n",
       "             'le': 465,\n",
       "             'samurai': 466,\n",
       "             'original': 467,\n",
       "             'element': 468,\n",
       "             'leon': 469,\n",
       "             'alain': 470,\n",
       "             'delon': 471,\n",
       "             'lonely': 472,\n",
       "             'warrior': 473,\n",
       "             'professional': 474,\n",
       "             'killer': 475,\n",
       "             'keep': 476,\n",
       "             'bird': 477,\n",
       "             'cage': 478,\n",
       "             'steal': 479,\n",
       "             'car': 480,\n",
       "             'exactly': 481,\n",
       "             'seek': 482,\n",
       "             'dignity': 483,\n",
       "             'gun': 484,\n",
       "             'world': 485,\n",
       "             'change': 486,\n",
       "             'realize': 487,\n",
       "             'place': 488,\n",
       "             'ghost': 489,\n",
       "             'dog': 490,\n",
       "             'jarmusch': 491,\n",
       "             'desperado': 492,\n",
       "             'rodriguez': 493,\n",
       "             'let': 494,\n",
       "             'girl': 495,\n",
       "             'natalie': 496,\n",
       "             'portman': 497,\n",
       "             'can´t': 498,\n",
       "             'point': 499,\n",
       "             'carbon': 500,\n",
       "             'celluloid': 501,\n",
       "             'rate': 502,\n",
       "             'macaulay': 503,\n",
       "             'connor': 504,\n",
       "             'follow': 505,\n",
       "             'track': 506,\n",
       "             'thing': 507,\n",
       "             'hear': 508,\n",
       "             'fool': 509,\n",
       "             'technically': 510,\n",
       "             'screw': 511,\n",
       "             'ramble': 512,\n",
       "             'fun': 513,\n",
       "             'enjoy': 514,\n",
       "             'piece': 515,\n",
       "             'utter': 516,\n",
       "             'drivel': 517,\n",
       "             'sense': 518,\n",
       "             'humor': 519,\n",
       "             'take': 520,\n",
       "             'seriously': 521,\n",
       "             'main': 522,\n",
       "             'aspect': 523,\n",
       "             'son': 524,\n",
       "             'terminally': 525,\n",
       "             'ill': 526,\n",
       "             'daddy': 527,\n",
       "             'decide': 528,\n",
       "             'hart': 529,\n",
       "             'transplant': 530,\n",
       "             'way': 531,\n",
       "             'true': 532,\n",
       "             'mad': 533,\n",
       "             'style': 534,\n",
       "             'gorilla': 535,\n",
       "             'trick': 536,\n",
       "             'potent': 537,\n",
       "             'sonny': 538,\n",
       "             'boy': 539,\n",
       "             'transform': 540,\n",
       "             'hideous': 541,\n",
       "             'ape': 542,\n",
       "             'immediately': 543,\n",
       "             'break': 544,\n",
       "             'spree': 545,\n",
       "             'horny': 546,\n",
       "             'beast': 547,\n",
       "             'hilarious': 548,\n",
       "             'putt': 549,\n",
       "             'turd': 550,\n",
       "             'talk': 551,\n",
       "             'excrement': 552,\n",
       "             'solid': 553,\n",
       "             'brown': 554,\n",
       "             'kind': 555,\n",
       "             'beautiful': 556,\n",
       "             'gore': 557,\n",
       "             'aside': 558,\n",
       "             'footage': 559,\n",
       "             'surgery': 560,\n",
       "             'incredibly': 561,\n",
       "             'fake': 562,\n",
       "             'nasty': 563,\n",
       "             'blood': 564,\n",
       "             'effect': 565,\n",
       "             'decapitation': 566,\n",
       "             'gouge': 567,\n",
       "             'throat': 568,\n",
       "             'rip': 569,\n",
       "             'scalp': 570,\n",
       "             'skull': 571,\n",
       "             'incomprehensible': 572,\n",
       "             'bloody': 573,\n",
       "             'notorious': 574,\n",
       "             'uk': 575,\n",
       "             'nasties': 576,\n",
       "             'ridiculous': 577,\n",
       "             'oh': 578,\n",
       "             'run': 579,\n",
       "             'needless': 580,\n",
       "             'la': 581,\n",
       "             'accurate': 582,\n",
       "             'title': 583,\n",
       "             'terrify': 584,\n",
       "             'tale': 585,\n",
       "             'horribly': 586,\n",
       "             'shock': 587,\n",
       "             'poorly': 588,\n",
       "             'stage': 589,\n",
       "             'random': 590,\n",
       "             'portrayal': 591,\n",
       "             'female': 592,\n",
       "             'nudity': 593,\n",
       "             'manage': 594,\n",
       "             'highly': 595,\n",
       "             'entertain': 596,\n",
       "             'ingredient': 597,\n",
       "             'nonsensical': 598,\n",
       "             'dialogue': 599,\n",
       "             'cardboard': 600,\n",
       "             'stupidity': 601,\n",
       "             'example': 602,\n",
       "             'maybe': 603,\n",
       "             'clearly': 604,\n",
       "             'designer': 605,\n",
       "             'wall': 606,\n",
       "             'door': 607,\n",
       "             'window': 608,\n",
       "             'etc': 609,\n",
       "             'build': 610,\n",
       "             'different': 611,\n",
       "             'interior': 612,\n",
       "             'e.g.': 613,\n",
       "             'hospital': 614,\n",
       "             'room': 615,\n",
       "             'unconscious': 616,\n",
       "             'wrestle': 617,\n",
       "             'lie': 618,\n",
       "             'suspiciously': 619,\n",
       "             'basement': 620,\n",
       "             'laboratory': 621,\n",
       "             'escape': 622,\n",
       "             'large': 623,\n",
       "             'conference': 624,\n",
       "             'grey': 625,\n",
       "             'one': 626,\n",
       "             'park': 627,\n",
       "             'studio': 628,\n",
       "             'occasion': 629,\n",
       "             'grass': 630,\n",
       "             'loose': 631,\n",
       "             'struggle': 632,\n",
       "             'fight': 633,\n",
       "             'shuffle': 634,\n",
       "             'concrete': 635,\n",
       "             'floor': 636,\n",
       "             'beneath': 637,\n",
       "             'mouth': 638,\n",
       "             'disappearance': 639,\n",
       "             'publicity': 640,\n",
       "             'intelligently': 641,\n",
       "             'colleague': 642,\n",
       "             'cleverly': 643,\n",
       "             'remark': 644,\n",
       "             'sleepwalker': 645,\n",
       "             'provide': 646,\n",
       "             'excuse': 647,\n",
       "             'investigate': 648,\n",
       "             'detective': 649,\n",
       "             'process': 650,\n",
       "             'logical': 651,\n",
       "             'deduction': 652,\n",
       "             'conclude': 653,\n",
       "             'superior': 654,\n",
       "             'murderer': 655,\n",
       "             'half': 656,\n",
       "             'answer': 657,\n",
       "             'absurd': 658,\n",
       "             'probable': 659,\n",
       "             'late': 660,\n",
       "             'television': 661,\n",
       "             'terror': 662,\n",
       "             'source': 663,\n",
       "             'laughter': 664,\n",
       "             'igor': 665,\n",
       "             'assistant': 666,\n",
       "             'kidnap': 667,\n",
       "             'zoo': 668,\n",
       "             'abduction': 669,\n",
       "             'candy': 670,\n",
       "             'speak': 671,\n",
       "             'lot': 672,\n",
       "             'papa': 673,\n",
       "             'scream': 674,\n",
       "             'dead': 675,\n",
       "             'periodically': 676,\n",
       "             'stop': 677,\n",
       "             'wallow': 678,\n",
       "             'concept': 679,\n",
       "             'replace': 680,\n",
       "             '2': 681,\n",
       "             'spectacular': 682,\n",
       "             'happen': 683,\n",
       "             'breast': 684,\n",
       "             'live': 685,\n",
       "             'beauty': 686,\n",
       "             'norma': 687,\n",
       "             'climactic': 688,\n",
       "             'contest': 689,\n",
       "             'near': 690,\n",
       "             'finale': 691,\n",
       "             'start': 692,\n",
       "             'motherly': 693,\n",
       "             'kong': 694,\n",
       "             'i.e.': 695,\n",
       "             'grind': 696,\n",
       "             'chip': 697,\n",
       "             'cent': 698,\n",
       "             'rational': 699,\n",
       "             'sleazy': 700,\n",
       "             'dreck': 701,\n",
       "             'worth': 702,\n",
       "             'waste': 703,\n",
       "             'unconvincing': 704,\n",
       "             'especially': 705,\n",
       "             'craig': 706,\n",
       "             'fong': 707,\n",
       "             'stiff': 708,\n",
       "             'nominally': 709,\n",
       "             'harry': 710,\n",
       "             'lee': 711,\n",
       "             'malaysian': 712,\n",
       "             'chinese': 713,\n",
       "             'descent': 714,\n",
       "             'country': 715,\n",
       "             'flunk': 716,\n",
       "             'cliche': 717,\n",
       "             'sex': 718,\n",
       "             'tension': 719,\n",
       "             'band': 720,\n",
       "             'member': 721,\n",
       "             'racial': 722,\n",
       "             'throw': 723,\n",
       "             'in.the': 724,\n",
       "             'subject': 725,\n",
       "             'adequately': 726,\n",
       "             'amateurish': 727,\n",
       "             'director': 728,\n",
       "             'contrive': 729,\n",
       "             'harden': 730,\n",
       "             'hair': 731,\n",
       "             'enjoyable': 732,\n",
       "             'numbingly': 733,\n",
       "             'weird': 734,\n",
       "             'motorama': 735,\n",
       "             'fit': 736,\n",
       "             'category': 737,\n",
       "             'endless': 738,\n",
       "             'appearance': 739,\n",
       "             'total': 740,\n",
       "             'merit': 741,\n",
       "             'delight': 742,\n",
       "             'improbability': 743,\n",
       "             'gus': 744,\n",
       "             'cuss': 745,\n",
       "             '10-year': 746,\n",
       "             'roadtrip': 747,\n",
       "             'imaginary': 748,\n",
       "             'collect': 749,\n",
       "             'game': 750,\n",
       "             'win': 751,\n",
       "             '$': 752,\n",
       "             'interact': 753,\n",
       "             'notice': 754,\n",
       "             'concern': 755,\n",
       "             'unbelievable': 756,\n",
       "             'consider': 757,\n",
       "             'unfazed': 758,\n",
       "             'disturb': 759,\n",
       "             'imagery': 760,\n",
       "             'depth': 761,\n",
       "             'hero': 762,\n",
       "             'cause': 763,\n",
       "             'misery': 764,\n",
       "             'encounter': 765,\n",
       "             'trouble': 766,\n",
       "             'mistreat': 767,\n",
       "             'strange': 768,\n",
       "             'wear': 769,\n",
       "             'share': 770,\n",
       "             'equally': 771,\n",
       "             'unmemorable': 772,\n",
       "             'negate': 773,\n",
       "             'name': 774,\n",
       "             'sign': 775,\n",
       "             'marquee': 776,\n",
       "             'value': 777,\n",
       "             'idea': 778,\n",
       "             'semblance': 779,\n",
       "             'script': 780,\n",
       "             'work': 781,\n",
       "             'incident': 782,\n",
       "             'last': 783,\n",
       "             'move': 784,\n",
       "             'allow': 785,\n",
       "             'connect': 786,\n",
       "             'jerk': 787,\n",
       "             'forth': 788,\n",
       "             'conveyor': 789,\n",
       "             'belt': 790,\n",
       "             'cease': 791,\n",
       "             'evolve': 792,\n",
       "             'level': 793,\n",
       "             'brat': 794,\n",
       "             'sneak': 795,\n",
       "             'rich': 796,\n",
       "             'note': 797,\n",
       "             'discover': 798,\n",
       "             'town': 799,\n",
       "             'actually': 800,\n",
       "             'research': 801,\n",
       "             'university': 802,\n",
       "             'maurice': 803,\n",
       "             'reality': 804,\n",
       "             'completely': 805,\n",
       "             'hollywood': 806,\n",
       "             'artistic': 807,\n",
       "             'license': 808,\n",
       "             'grant': 809,\n",
       "             'dr': 810,\n",
       "             'totally': 811,\n",
       "             'endorse': 812,\n",
       "             'cure': 813,\n",
       "             'insanity': 814,\n",
       "             'practice': 815,\n",
       "             'liberal': 816,\n",
       "             'represent': 817,\n",
       "             'laughable': 818,\n",
       "             'critic': 819,\n",
       "             'legitimate': 820,\n",
       "             'newspaper': 821,\n",
       "             'historical': 822,\n",
       "             'basis': 823,\n",
       "             'actual': 824,\n",
       "             'friendship': 825,\n",
       "             'walt': 826,\n",
       "             'whitman': 827,\n",
       "             'disregard': 828,\n",
       "             'horror': 829,\n",
       "             'experience': 830,\n",
       "             'glorify': 831,\n",
       "             'industry': 832,\n",
       "             'charm': 833,\n",
       "             'powerful': 834,\n",
       "             'anthony': 835,\n",
       "             'minghella': 836,\n",
       "             'enthrall': 837,\n",
       "             'winner': 838,\n",
       "             'english': 839,\n",
       "             'patient': 840,\n",
       "             'mid': 841,\n",
       "             '90s': 842,\n",
       "             'initial': 843,\n",
       "             'have': 844,\n",
       "             'lose': 845,\n",
       "             'nerve': 846,\n",
       "             'grand': 847,\n",
       "             'project': 848,\n",
       "             'create': 849,\n",
       "             'sweep': 850,\n",
       "             'majesty': 851,\n",
       "             'craft': 852,\n",
       "             'lawrence': 853,\n",
       "             'arabia': 854,\n",
       "             'commandment': 855,\n",
       "             'glorious': 856,\n",
       "             'stretch': 857,\n",
       "             'hardly': 858,\n",
       "             'long': 859,\n",
       "             'fascinate': 860,\n",
       "             'past': 861,\n",
       "             'novel': 862,\n",
       "             'ondaatje': 863,\n",
       "             'godfather': 864,\n",
       "             'ii': 865,\n",
       "             'construct': 866,\n",
       "             'blend': 867,\n",
       "             'present': 868,\n",
       "             'revolve': 869,\n",
       "             'titular': 870,\n",
       "             'post': 871,\n",
       "             'war': 872,\n",
       "             'ralph': 873,\n",
       "             'fiennes': 874,\n",
       "             'scar': 875,\n",
       "             'plane': 876,\n",
       "             'crash': 877,\n",
       "             'isolate': 878,\n",
       "             'church': 879,\n",
       "             'single': 880,\n",
       "             'nurse': 881,\n",
       "             'marvelously': 882,\n",
       "             'juliette': 883,\n",
       "             'binoche': 884,\n",
       "             'apart': 885,\n",
       "             'bond': 886,\n",
       "             'raspy': 887,\n",
       "             'voice': 888,\n",
       "             'learn': 889,\n",
       "             'willem': 890,\n",
       "             'dafoe': 891,\n",
       "             'arrive': 892,\n",
       "             'appear': 893,\n",
       "             'beautifully': 894,\n",
       "             'shape': 895,\n",
       "             'dye': 896,\n",
       "             'mix': 897,\n",
       "             'affair': 898,\n",
       "             'tragically': 899,\n",
       "             'blunt': 900,\n",
       "             'epic': 901,\n",
       "             'sensation': 902,\n",
       "             'magnificently': 903,\n",
       "             'admire': 904,\n",
       "             'kristin': 905,\n",
       "             'thomas': 906,\n",
       "             'passionate': 907,\n",
       "             'obsessive': 908,\n",
       "             'enchant': 909,\n",
       "             'usually': 910,\n",
       "             'cold': 911,\n",
       "             'mountain': 912,\n",
       "             'romantic': 913,\n",
       "             'lustful': 914,\n",
       "             'tend': 915,\n",
       "             'associate': 916,\n",
       "             'lust': 917,\n",
       "             'develope': 918,\n",
       "             'rush': 919,\n",
       "             'exploit': 920,\n",
       "             'proportion': 921,\n",
       "             'believe': 922,\n",
       "             'remind': 923,\n",
       "             'vertigo': 924,\n",
       "             'performer': 925,\n",
       "             'being': 926,\n",
       "             'fall': 927,\n",
       "             'performance': 928,\n",
       "             'oscar': 929,\n",
       "             'sort': 930,\n",
       "             'questionable': 931,\n",
       "             'quintessential': 932,\n",
       "             'enormous': 933,\n",
       "             'enthusiasm': 934,\n",
       "             'dishonest': 935,\n",
       "             'describe': 936,\n",
       "             'flaw': 937,\n",
       "             'glance': 938,\n",
       "             'reason': 939,\n",
       "             'complaint': 940,\n",
       "             'unnecessary': 941,\n",
       "             'subplot': 942,\n",
       "             'particularly': 943,\n",
       "             'bomb': 944,\n",
       "             'specialist': 945,\n",
       "             'naveen': 946,\n",
       "             'andrews': 947,\n",
       "             'assume': 948,\n",
       "             'book': 949,\n",
       "             'perfectly': 950,\n",
       "             'distract': 951,\n",
       "             'relationship': 952,\n",
       "             'easily': 953,\n",
       "             'forgivable': 954,\n",
       "             'slow': 955,\n",
       "             'extraordinary': 956,\n",
       "             'achievement': 957,\n",
       "             'insane': 958,\n",
       "             'casablanca': 959,\n",
       "             'remarkable': 960,\n",
       "             'effective': 961,\n",
       "             'gift': 962,\n",
       "             'filmmaker': 963,\n",
       "             'evidence': 964,\n",
       "             'anybody': 965,\n",
       "             'winchester': 966,\n",
       "             'everyday': 967,\n",
       "             'western': 968,\n",
       "             'rifle': 969,\n",
       "             'pass': 970,\n",
       "             'mechanism': 971,\n",
       "             'rock': 972,\n",
       "             'hudson': 973,\n",
       "             'indian': 974,\n",
       "             'chief': 975,\n",
       "             'jimmy': 976,\n",
       "             'stewart': 977,\n",
       "             'strength': 978,\n",
       "             'shelly': 979,\n",
       "             'winter': 980,\n",
       "             'gal': 981,\n",
       "             'cope': 982,\n",
       "             'wild': 983,\n",
       "             'west': 984,\n",
       "             'important': 985,\n",
       "             'politically': 986,\n",
       "             'correct': 987,\n",
       "             'type': 988,\n",
       "             'indians': 989,\n",
       "             'remorse': 990,\n",
       "             'standard': 991,\n",
       "             'pretty': 992,\n",
       "             'violent': 993,\n",
       "             'challenge': 994,\n",
       "             'artwork': 995,\n",
       "             'unsurpassed': 996,\n",
       "             'cry': 997,\n",
       "             'dunno': 998,\n",
       "             'zentropa': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_iterator.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_0': tensor([[  135,   173,  2685,  ...,     6,   335,     2],\n",
      "        [   28,  1600,     7,  ...,   703,   323,     2],\n",
      "        [ 1276,   163,   173,  ...,   181,    80,     2],\n",
      "        ...,\n",
      "        [   28, 19217,     7,  ...,   292,  1233,     2],\n",
      "        [ 5551,  1867,   889,  ...,    23,     2,     0],\n",
      "        [ 8425,  5020,  1000,  ...,   755,     2,     0]]),\n",
      " 'input_1': tensor([ 0.3280,  0.0333,  0.0146, -0.1302, -0.0811,  0.0029, -0.2673,  0.5180,\n",
      "         0.2483,  0.0739,  0.0571,  0.0545,  0.1115,  0.4592,  0.2960,  0.4360,\n",
      "        -0.0438,  0.1438, -0.0969,  0.3300, -0.0528,  0.2960, -0.4077,  0.3357,\n",
      "         0.0596, -0.2222, -0.0294, -0.1250,  0.0578, -0.2844, -0.0988,  0.2455]),\n",
      " 'input_2': tensor([ 93, 113, 113,  84,  93, 122,  96,  97, 118, 111, 111, 103, 104, 108,\n",
      "        105, 113,  97,  61,  99,  89, 126, 122,  93, 113, 151,  83, 108,  86,\n",
      "        101, 101, 110,  72]),\n",
      " 'target': tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]),\n",
      " 'x_lengths': tensor([39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 38, 38])}\n"
     ]
    }
   ],
   "source": [
    "# Run the BatchIterator and print the first set of batches\n",
    "for batches in val_iterator:\n",
    "    pprint(batches)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we are going to create the neural network model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
